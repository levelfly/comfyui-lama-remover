# /nodes/remover.py (æ¥µé™å„ªåŒ–ç‰ˆæœ¬ï¼šå–®ä¾‹æ¨¡å‹ + æ‰¹è™•ç† + å…§å­˜æ±  + æ€§èƒ½ç›£æ§)

import torch
import torch.nn.functional as F
from torchvision import transforms
import time
import gc
from typing import Tuple, Optional, List
from contextlib import contextmanager

# å¾æˆ‘å€‘è‡ªæœ‰çš„ lama å¥—ä»¶ä¸­åŒ¯å…¥æ¨¡å‹å®šç¾©
from ..lama import model

# --- å¸¸é‡å®šç¾© ---
MODEL_INPUT_SIZE = 512  # LaMa æ¨¡å‹çš„æ¨™æº–è¼¸å…¥å°ºå¯¸
DEFAULT_MASK_THRESHOLD = 128
DEFAULT_BLUR_RADIUS = 10
MAX_BATCH_SIZE = 4  # RTX 3090 çš„æœ€ä½³æ‰¹è™•ç†å¤§å°

# --- [æ¥µé™æ•ˆèƒ½èåˆ] ---
try:
    from lama_cpp import _C as custom_cuda_blur

    LAMA_CPP_AVAILABLE = True
    print("âœ… æˆåŠŸåŒ¯å…¥è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚å·²å•Ÿç”¨æ¥µé™æ•ˆèƒ½æ¨¡å¼ã€‚")
except ImportError:
    LAMA_CPP_AVAILABLE = False
    print("âš ï¸  æœªæ‰¾åˆ°è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚å°‡ä½¿ç”¨ PyTorch åŸç”Ÿæ¨¡ç³Šè™•ç†ã€‚")
    from PIL import ImageFilter


# --- [å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨] ---
class LamaModelManager:
    """
    å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨ï¼Œé¿å…é‡è¤‡è¼‰å…¥ TensorRT å¼•æ“
    """
    _instance = None
    _model = None
    _device = None
    _is_initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LamaModelManager, cls).__new__(cls)
        return cls._instance

    @property
    def model(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._model

    @property
    def device(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._device

    def _initialize_model(self):
        """æƒ°æ€§åˆå§‹åŒ–æ¨¡å‹"""
        if self._is_initialized:
            return

        print("ğŸ”„ åˆå§‹åŒ– LaMa TensorRT æ¨¡å‹...")
        start_time = time.time()

        try:
            self._model = model.BigLama()
            self._device = self._model.device

            # é ç†±æ¨¡å‹ä»¥å„ªåŒ–é¦–æ¬¡æ¨ç†é€Ÿåº¦
            self._warmup_model()

            init_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚: {init_time:.2f}s")

            self._is_initialized = True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _warmup_model(self):
        """é ç†±æ¨¡å‹ä»¥å„ªåŒ–é¦–æ¬¡æ¨ç†"""
        print("ğŸ”¥ åŸ·è¡Œæ¨¡å‹é ç†±...")
        try:
            # å‰µå»ºè™›æ“¬è¼¸å…¥é€²è¡Œé ç†±
            dummy_image = torch.randn(1, 3, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE,
                                      device=self._model.device, dtype=torch.float32)
            dummy_mask = torch.randn(1, 1, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE,
                                     device=self._model.device, dtype=torch.float32)

            # åŸ·è¡Œå¹¾æ¬¡é ç†±æ¨ç†
            for _ in range(3):
                with torch.no_grad():
                    _ = self._model(dummy_image, dummy_mask)
                    torch.cuda.synchronize()

            print("âœ… æ¨¡å‹é ç†±å®Œæˆ")

        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹é ç†±å¤±æ•—: {e}")


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å¯¦ä¾‹
model_manager = LamaModelManager()


# --- [å…§å­˜æ± ç®¡ç†å™¨] ---
class TensorPool:
    """
    å¼µé‡å…§å­˜æ± ï¼Œé‡ç”¨å¼µé‡ä»¥æ¸›å°‘å…§å­˜åˆ†é…é–‹éŠ·
    """

    def __init__(self, device):
        self.device = device
        self.pools = {}  # æŒ‰å½¢ç‹€åˆ†çµ„çš„å¼µé‡æ± 

    def get_tensor(self, shape, dtype=torch.float32):
        """ç²å–æŒ‡å®šå½¢ç‹€çš„å¼µé‡"""
        key = (tuple(shape), dtype)

        if key not in self.pools:
            self.pools[key] = []

        pool = self.pools[key]

        if pool:
            tensor = pool.pop()
            tensor.zero_()  # æ¸…é›¶é‡ç”¨
            return tensor
        else:
            return torch.zeros(shape, dtype=dtype, device=self.device)

    def return_tensor(self, tensor):
        """æ­¸é‚„å¼µé‡åˆ°æ± ä¸­"""
        key = (tuple(tensor.shape), tensor.dtype)

        if key not in self.pools:
            self.pools[key] = []

        # é™åˆ¶æ± å¤§å°é¿å…å…§å­˜æ´©æ¼
        if len(self.pools[key]) < 10:
            self.pools[key].append(tensor.detach())


# --- [é«˜æ€§èƒ½æ¨¡ç³Šè™•ç†] ---
class BlurProcessor:
    """
    é«˜æ€§èƒ½æ¨¡ç³Šè™•ç†å™¨ï¼Œæ”¯æŒæ‰¹è™•ç†å’Œ CUDA åŠ é€Ÿ
    """

    @staticmethod
    def apply_blur(mask_tensor: torch.Tensor, radius: int) -> torch.Tensor:
        """
        æ‡‰ç”¨é«˜æ–¯æ¨¡ç³Šï¼Œè‡ªå‹•é¸æ“‡æœ€ä½³å¯¦ç¾
        """
        if radius <= 0:
            return mask_tensor

        if LAMA_CPP_AVAILABLE:
            # ä½¿ç”¨è‡ªå®šç¾© CUDA æ ¸å¿ƒï¼ˆæœ€å¿«ï¼‰
            return custom_cuda_blur.gaussian_blur(mask_tensor, radius)
        else:
            # ä½¿ç”¨ PyTorch åŸç”Ÿå¯¦ç¾ï¼ˆè¼ƒå¿«ï¼‰
            return BlurProcessor._pytorch_gaussian_blur(mask_tensor, radius)

    @staticmethod
    def _pytorch_gaussian_blur(tensor: torch.Tensor, radius: int) -> torch.Tensor:
        """
        ä½¿ç”¨ PyTorch å¯¦ç¾çš„æ‰¹è™•ç†é«˜æ–¯æ¨¡ç³Š
        """
        # è¨ˆç®—é«˜æ–¯æ ¸å¤§å°
        kernel_size = 2 * radius + 1

        # å‰µå»ºé«˜æ–¯æ ¸
        sigma = radius / 3.0
        x = torch.arange(kernel_size, dtype=torch.float32, device=tensor.device)
        x = x - kernel_size // 2
        gauss = torch.exp(-0.5 * (x / sigma) ** 2)
        gauss = gauss / gauss.sum()

        # é‡å¡‘ç‚º 2D æ ¸
        gauss = gauss.view(1, 1, 1, -1)

        # æ‡‰ç”¨å¯åˆ†é›¢çš„é«˜æ–¯æ¨¡ç³Šï¼ˆæ°´å¹³ + å‚ç›´ï¼‰
        # æ°´å¹³æ¨¡ç³Š
        padding = kernel_size // 2
        tensor = F.conv2d(tensor, gauss, padding=(0, padding), groups=tensor.shape[1])
        # å‚ç›´æ¨¡ç³Š
        tensor = F.conv2d(tensor, gauss.transpose(-1, -2), padding=(padding, 0), groups=tensor.shape[1])

        return tensor


# --- [æ€§èƒ½ç›£æ§] ---
@contextmanager
def performance_monitor(operation_name: str):
    """æ€§èƒ½ç›£æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_time = time.time()
    start_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0

    try:
        yield
    finally:
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0

        elapsed_time = end_time - start_time
        memory_delta = (end_memory - start_memory) / 1024 / 1024  # MB

        print(f"â±ï¸  {operation_name}: {elapsed_time:.3f}s, å…§å­˜è®ŠåŒ–: {memory_delta:+.1f}MB")


# --- [å„ªåŒ–çš„ä¸»ç¯€é»é¡] ---
class LamaRemover:
    """
    æ¥µé™å„ªåŒ–çš„ LaMa ç§»é™¤ç¯€é»
    ç‰¹é»ï¼š
    - å–®ä¾‹æ¨¡å‹ç®¡ç†ï¼Œé¿å…é‡è¤‡è¼‰å…¥
    - æ™ºèƒ½æ‰¹è™•ç†ï¼Œå……åˆ†åˆ©ç”¨ RTX 3090
    - å…§å­˜æ± ç®¡ç†ï¼Œæ¸›å°‘åˆ†é…é–‹éŠ·
    - æ€§èƒ½ç›£æ§ï¼Œå¯¦æ™‚è¿½è¹¤æ•ˆèƒ½
    """

    def __init__(self):
        self.tensor_pool = None  # æƒ°æ€§åˆå§‹åŒ–

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "masks": ("MASK",),
                "mask_threshold": ("INT", {
                    "default": DEFAULT_MASK_THRESHOLD,
                    "min": 0, "max": 255, "step": 1
                }),
                "gaussblur_radius": ("INT", {
                    "default": DEFAULT_BLUR_RADIUS,
                    "min": 0, "max": 50, "step": 1
                }),
                "invert_mask": ("BOOLEAN", {"default": False}),
                "batch_size": ("INT", {
                    "default": 1, "min": 1, "max": MAX_BATCH_SIZE, "step": 1,
                    "tooltip": "æ‰¹è™•ç†å¤§å°ï¼ŒRTX 3090 å»ºè­° 2-4"
                }),
                "enable_performance_monitor": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å•Ÿç”¨æ€§èƒ½ç›£æ§ï¼ˆæœƒè¼•å¾®å½±éŸ¿æ€§èƒ½ï¼‰"
                }),
            },
        }

    CATEGORY = "LamaRemover"
    RETURN_NAMES = ("images",)
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "lama_remover"

    def _initialize_tensor_pool(self):
        """æƒ°æ€§åˆå§‹åŒ–å¼µé‡æ± """
        if self.tensor_pool is None:
            self.tensor_pool = TensorPool(model_manager.device)

    def _normalize_tensorrt_output(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        æ­£ç¢ºæ­¸ä¸€åŒ– TensorRT è¼¸å‡ºï¼Œç¶­æŒåŸç‰ˆé‚è¼¯é¿å…éæ›
        TensorRT çš„è¼¸å‡ºç¯„åœå¯èƒ½ä¸æ˜¯æ¨™æº–çš„ [0, 1]ï¼Œéœ€è¦å…ˆåš min-max æ­¸ä¸€åŒ–
        """
        # å°æ¯å€‹æ¨£æœ¬åˆ†åˆ¥é€²è¡Œæ­¸ä¸€åŒ–ï¼ˆæ‰¹è™•ç†ç‰ˆæœ¬ï¼‰
        normalized_tensors = []

        for i in range(tensor.shape[0]):
            sample = tensor[i:i + 1]  # ä¿æŒç¶­åº¦ (1, C, H, W)

            # ç²å–ç•¶å‰æ¨£æœ¬çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
            min_val = torch.min(sample)
            max_val = torch.max(sample)

            # èª¿è©¦ä¿¡æ¯ï¼šé¡¯ç¤º TensorRT åŸå§‹è¼¸å‡ºç¯„åœ
            print(f"ğŸ” æ¨£æœ¬ {i + 1} TensorRT åŸå§‹è¼¸å‡ºç¯„åœ: [{min_val.item():.4f}, {max_val.item():.4f}]")

            # é¿å…é™¤é›¶éŒ¯èª¤ï¼šåªæœ‰ç•¶ max > min æ™‚æ‰é€²è¡Œæ­¸ä¸€åŒ–
            if max_val > min_val:
                # min-max æ­¸ä¸€åŒ–ï¼šå°‡ [min, max] æ˜ å°„åˆ° [0, 1]
                normalized_sample = (sample - min_val) / (max_val - min_val)
                print(f"âœ… æ¨£æœ¬ {i + 1} æ­¸ä¸€åŒ–å¾Œç¯„åœ: [0.0000, 1.0000]")
            else:
                # å¦‚æœ min == maxï¼Œç›´æ¥è¨­ç‚º 0ï¼ˆé¿å… NaNï¼‰
                normalized_sample = torch.zeros_like(sample)
                print(f"âš ï¸  æ¨£æœ¬ {i + 1} min==maxï¼Œè¨­ç‚ºé›¶å€¼")

            # æœ€çµ‚ clamp ç¢ºä¿åš´æ ¼åœ¨ [0, 1] ç¯„åœå…§
            normalized_sample = torch.clamp(normalized_sample, 0.0, 1.0)
            normalized_tensors.append(normalized_sample)

        # åˆä½µæ‰€æœ‰æ­¸ä¸€åŒ–å¾Œçš„æ¨£æœ¬
        return torch.cat(normalized_tensors, dim=0)

    def _validate_inputs(self, images: torch.Tensor, masks: torch.Tensor) -> bool:
        """é©—è­‰è¼¸å…¥å¼µé‡"""
        if images.shape[0] != masks.shape[0]:
            print(f"âŒ åœ–åƒå’Œé®ç½©çš„æ‰¹æ¬¡å¤§å°ä¸åŒ¹é…: {images.shape[0]} vs {masks.shape[0]}")
            return False

        if len(images.shape) != 4 or len(masks.shape) != 3:
            print(f"âŒ è¼¸å…¥å¼µé‡ç¶­åº¦ä¸æ­£ç¢º: images {images.shape}, masks {masks.shape}")
            return False

        return True

    def _prepare_batch_tensors(self, images: torch.Tensor, masks: torch.Tensor,
                               batch_indices: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:
        """æº–å‚™æ‰¹è™•ç†å¼µé‡"""
        self._initialize_tensor_pool()

        batch_size = len(batch_indices)
        device = model_manager.device

        # å¾æ± ä¸­ç²å–æˆ–å‰µå»ºå¼µé‡
        batch_images = self.tensor_pool.get_tensor(
            (batch_size, 3, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)
        )
        batch_masks = self.tensor_pool.get_tensor(
            (batch_size, 1, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)
        )

        # å¡«å……æ‰¹è™•ç†æ•¸æ“š
        for i, idx in enumerate(batch_indices):
            # è™•ç†åœ–åƒ
            image = images[idx].permute(2, 0, 1).unsqueeze(0)  # HWC -> BCHW
            image_resized = transforms.functional.resize(
                image, (MODEL_INPUT_SIZE, MODEL_INPUT_SIZE),
                interpolation=transforms.InterpolationMode.BILINEAR,
                antialias=True
            )
            batch_images[i] = image_resized.squeeze(0).to(device)

            # è™•ç†é®ç½©
            mask = masks[idx]
            if mask.ndim == 3:
                mask = mask[:, :, 0]  # å–ç¬¬ä¸€å€‹é€šé“
            mask = mask.unsqueeze(0).unsqueeze(0)  # HW -> BCHW
            mask_resized = transforms.functional.resize(
                mask, (MODEL_INPUT_SIZE, MODEL_INPUT_SIZE),
                interpolation=transforms.InterpolationMode.NEAREST
            )
            batch_masks[i] = mask_resized.squeeze(0).to(device)

        return batch_images, batch_masks

    def _postprocess_results(self, results: torch.Tensor, original_shapes: List[Tuple[int, int]],
                             batch_indices: List[int]) -> List[torch.Tensor]:
        """å¾Œè™•ç†çµæœå¼µé‡"""
        processed_results = []

        for i, idx in enumerate(batch_indices):
            result = results[i:i + 1]  # ä¿æŒæ‰¹æ¬¡ç¶­åº¦
            h, w = original_shapes[idx]

            # ç¸®æ”¾å›åŸå§‹å°ºå¯¸
            result_resized = transforms.functional.resize(
                result, (h, w),
                interpolation=transforms.InterpolationMode.BILINEAR,
                antialias=True
            )

            # è½‰æ›ç‚º ComfyUI æ ¼å¼ (BCHW -> BHWC)
            result_comfy = result_resized.permute(0, 2, 3, 1).cpu()
            processed_results.append(result_comfy)

            # æ­¸é‚„å¼µé‡åˆ°æ± ä¸­
            if hasattr(self, 'tensor_pool') and self.tensor_pool:
                self.tensor_pool.return_tensor(result.detach())

        return processed_results

    def lama_remover(self, images: torch.Tensor, masks: torch.Tensor,
                     mask_threshold: int, gaussblur_radius: int, invert_mask: bool,
                     batch_size: int = 1, enable_performance_monitor: bool = False):
        """
        å„ªåŒ–çš„æ ¸å¿ƒè™•ç†å‡½å¼
        """
        # è¼¸å…¥é©—è­‰
        if not self._validate_inputs(images, masks):
            return (images,)

        # æ€§èƒ½ç›£æ§è£é£¾å™¨
        monitor = performance_monitor if enable_performance_monitor else lambda x: contextmanager(lambda: (yield))()

        with monitor("ç¸½è™•ç†æ™‚é–“"):
            # æº–å‚™è™•ç†
            num_images = images.shape[0]
            results = []

            # è¨˜éŒ„åŸå§‹å½¢ç‹€
            original_shapes = [(images.shape[1], images.shape[2])] * num_images

            # æ‰¹è™•ç†å¾ªç’°
            for start_idx in range(0, num_images, batch_size):
                end_idx = min(start_idx + batch_size, num_images)
                batch_indices = list(range(start_idx, end_idx))
                current_batch_size = len(batch_indices)

                with monitor(f"æ‰¹æ¬¡ {start_idx // batch_size + 1}/{(num_images - 1) // batch_size + 1}"):
                    try:
                        # æº–å‚™æ‰¹è™•ç†æ•¸æ“š
                        with monitor("æ•¸æ“šæº–å‚™"):
                            batch_images, batch_masks = self._prepare_batch_tensors(
                                images, masks, batch_indices
                            )

                        # é®ç½©é è™•ç†
                        with monitor("é®ç½©è™•ç†"):
                            if invert_mask:
                                batch_masks = 1.0 - batch_masks

                            # æ‡‰ç”¨æ¨¡ç³Š
                            if gaussblur_radius > 0:
                                batch_masks = BlurProcessor.apply_blur(batch_masks, gaussblur_radius)

                            # äºŒå€¼åŒ–
                            threshold = mask_threshold / 255.0
                            batch_masks = (batch_masks > threshold).float()

                        # æ¨¡å‹æ¨ç†
                        with monitor("TensorRT æ¨ç†"):
                            with torch.no_grad():
                                # èª¿è©¦ï¼šé¡¯ç¤ºè¼¸å…¥æ•¸å€¼ç¯„åœï¼ˆä¿ç•™åŸç‰ˆé‚è¼¯ï¼‰
                                print(f"ğŸ“Š è¼¸å…¥åœ–ç‰‡æ•¸å€¼ç¯„åœ: [{batch_images.min().item():.4f}, {batch_images.max().item():.4f}]")
                                print(f"ğŸ“Š è¼¸å…¥é®ç½©æ•¸å€¼ç¯„åœ: [{batch_masks.min().item():.4f}, {batch_masks.max().item():.4f}]")

                                batch_results = model_manager.model(batch_images, batch_masks)
                                torch.cuda.synchronize()  # ç¢ºä¿ GPU æ“ä½œå®Œæˆ

                        # çµæœå¾Œè™•ç†
                        with monitor("çµæœå¾Œè™•ç†"):
                            # æ‰‹å‹•æ­¸ä¸€åŒ– TensorRT çš„è¼¸å‡ºï¼ˆé—œéµï¼ç¶­æŒåŸç‰ˆé‚è¼¯ï¼‰
                            # âš ï¸ é‡è¦ï¼šTensorRT è¼¸å‡ºç¯„åœå¯èƒ½ä¸æ˜¯ [0, 1]ï¼Œå¿…é ˆå…ˆæ­£ç¢ºæ­¸ä¸€åŒ–é¿å…éæ›
                            # åŸç‰ˆé‚è¼¯ï¼šmin-max normalization + clampï¼Œä¸å¯ç°¡åŒ–ï¼
                            batch_results = self._normalize_tensorrt_output(batch_results)

                            # è™•ç†æ¯å€‹çµæœ
                            processed = self._postprocess_results(
                                batch_results, original_shapes, batch_indices
                            )
                            results.extend(processed)

                    except Exception as e:
                        print(f"âŒ æ‰¹æ¬¡ {start_idx // batch_size + 1} è™•ç†å¤±æ•—: {e}")
                        # å‚™æ´ï¼šè¿”å›åŸå§‹åœ–åƒ
                        for idx in batch_indices:
                            results.append(images[idx:idx + 1])

                    # åŠæ™‚æ¸…ç† GPU å…§å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

        # åˆä½µæ‰€æœ‰çµæœ
        try:
            final_result = torch.cat(results, dim=0)
        except Exception as e:
            print(f"âŒ çµæœåˆä½µå¤±æ•—: {e}")
            final_result = images

        # æœ€çµ‚å…§å­˜æ¸…ç†
        if enable_performance_monitor:
            print(f"ğŸ§¹ æœ€çµ‚ GPU å…§å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024 / 1024:.1f}MB")

        return (final_result,)


class LamaRemoverIMG(LamaRemover):
    """
    LamaRemover çš„ IMAGE è¼¸å…¥è®Šé«”ï¼Œç¹¼æ‰¿æ‰€æœ‰å„ªåŒ–
    """

    @classmethod
    def INPUT_TYPES(cls):
        base_inputs = super().INPUT_TYPES()
        base_inputs["required"]["masks"] = ("IMAGE",)  # æ”¹ç‚º IMAGE é¡å‹
        return base_inputs

    FUNCTION = "lama_remover"


# --- [å·¥å…·å‡½æ•¸] ---
def get_model_info():
    """ç²å–æ¨¡å‹è³‡è¨Šï¼ˆé™¤éŒ¯ç”¨ï¼‰"""
    try:
        info = model_manager.model.get_engine_info()
        return info
    except Exception as e:
        return {"error": str(e)}


def cleanup_resources():
    """æ¸…ç†è³‡æºï¼ˆå¯é¸çš„å¤–éƒ¨èª¿ç”¨ï¼‰"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()
    print("ğŸ§¹ è³‡æºæ¸…ç†å®Œæˆ")


# --- ComfyUI ç¯€é»è¨»å†Š ---
NODE_CLASS_MAPPINGS = {
    "LamaRemover": LamaRemover,
    "LamaRemoverIMG": LamaRemoverIMG
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LamaRemover": "ğŸš€ Big Lama Remover (æ¥µé™å„ªåŒ–ç‰ˆ)",
    "LamaRemoverIMG": "ğŸš€ Big Lama Remover IMG (æ¥µé™å„ªåŒ–ç‰ˆ)"
}