# /nodes/remover.py (å‹•æ…‹å°ºå¯¸å„ªåŒ–ç‰ˆï¼šå–®ä¾‹æ¨¡å‹ + Padding/Cropping + æ€§èƒ½ç›£æ§)

import torch
import torch.nn.functional as F
from torchvision import transforms
import time
import gc
from typing import Tuple, Optional, List
from contextlib import contextmanager
import math

# å¾æˆ‘å€‘è‡ªæœ‰çš„ lama å¥—ä»¶ä¸­åŒ¯å…¥æ¨¡å‹å®šç¾©
from ..lama import model

# --- å¸¸é‡å®šç¾© (MODIFIED) ---
# MODEL_INPUT_SIZE å·²è¢«ç§»é™¤ï¼Œå› ç‚ºæˆ‘å€‘ä¸å†ä½¿ç”¨å›ºå®šå°ºå¯¸
PADDING_FACTOR = 32  # LaMa æ¨¡å‹é€šå¸¸è¦æ±‚è¼¸å…¥å°ºå¯¸æ˜¯ 8 çš„å€æ•¸
DEFAULT_MASK_THRESHOLD = 128
DEFAULT_BLUR_RADIUS = 10
MAX_BATCH_SIZE = 1  # å°æ–¼å‹•æ…‹å°ºå¯¸ï¼Œå»ºè­°æ‰¹æ¬¡ç‚º 1 ä»¥ç°¡åŒ–å…§å­˜ç®¡ç†

# --- [æ¥µé™æ•ˆèƒ½èåˆ] ---
try:
    from lama_cpp import _C as custom_cuda_blur

    LAMA_CPP_AVAILABLE = True
    print("âœ… æˆåŠŸåŒ¯å…¥è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚å·²å•Ÿç”¨æ¥µé™æ•ˆèƒ½æ¨¡å¼ã€‚")
except ImportError:
    LAMA_CPP_AVAILABLE = False
    print("âš ï¸  æœªæ‰¾åˆ°è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚å°‡ä½¿ç”¨ PyTorch åŸç”Ÿæ¨¡ç³Šè™•ç†ã€‚")
    from PIL import ImageFilter


# --- [å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨] ---
class LamaModelManager:
    """
    å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨ï¼Œé¿å…é‡è¤‡è¼‰å…¥ TensorRT å¼•æ“
    """
    _instance = None
    _model = None
    _device = None
    _is_initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LamaModelManager, cls).__new__(cls)
        return cls._instance

    @property
    def model(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._model

    @property
    def device(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._device

    def _initialize_model(self):
        """æƒ°æ€§åˆå§‹åŒ–æ¨¡å‹"""
        if self._is_initialized:
            return

        print("ğŸ”„ åˆå§‹åŒ– LaMa TensorRT æ¨¡å‹...")
        start_time = time.time()

        try:
            self._model = model.BigLama()
            self._device = self._model.device

            # å°æ–¼å‹•æ…‹å°ºå¯¸å¼•æ“ï¼Œä½¿ç”¨ä¸€å€‹å¸¸è¦‹å°ºå¯¸é€²è¡Œé ç†±
            self._warmup_model(512, 512)

            init_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚: {init_time:.2f}s")

            self._is_initialized = True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _warmup_model(self, height, width):
        """é ç†±æ¨¡å‹ä»¥å„ªåŒ–é¦–æ¬¡æ¨ç†"""
        print(f"ğŸ”¥ åŸ·è¡Œæ¨¡å‹é ç†± (å°ºå¯¸: {height}x{width})...")
        try:
            # å‰µå»ºè™›æ“¬è¼¸å…¥é€²è¡Œé ç†±
            dummy_image = torch.randn(1, 3, height, width,
                                      device=self._model.device, dtype=torch.float32)
            dummy_mask = torch.randn(1, 1, height, width,
                                     device=self._model.device, dtype=torch.float32)

            # åŸ·è¡Œå¹¾æ¬¡é ç†±æ¨ç†
            for _ in range(3):
                with torch.no_grad():
                    _ = self._model(dummy_image, dummy_mask)
                    torch.cuda.synchronize()

            print("âœ… æ¨¡å‹é ç†±å®Œæˆ")

        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹é ç†±å¤±æ•—: {e}")


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å¯¦ä¾‹
model_manager = LamaModelManager()


# --- [å…§å­˜æ± ç®¡ç†å™¨] ---
# å‚™è¨»ï¼šå°æ–¼å‹•æ…‹å°ºå¯¸ï¼Œå‚³çµ±çš„å…§å­˜æ± æ•ˆæœæœ‰é™ï¼Œå› ç‚ºå½¢ç‹€ä¸æ–·è®ŠåŒ–ã€‚æ­¤è™•ä¿ç•™çµæ§‹ä½†å½±éŸ¿é™ä½ã€‚
class TensorPool:
    """
    å¼µé‡å…§å­˜æ± ï¼Œé‡ç”¨å¼µé‡ä»¥æ¸›å°‘å…§å­˜åˆ†é…é–‹éŠ·
    """

    def __init__(self, device):
        self.device = device
        self.pools = {}

    def get_tensor(self, shape, dtype=torch.float32):
        key = (tuple(shape), dtype)
        if key not in self.pools: self.pools[key] = []
        pool = self.pools[key]
        return pool.pop().zero_() if pool else torch.zeros(shape, dtype=dtype, device=self.device)

    def return_tensor(self, tensor):
        key = (tuple(tensor.shape), tensor.dtype)
        if key not in self.pools: self.pools[key] = []
        if len(self.pools[key]) < 10: self.pools[key].append(tensor.detach())


# --- [é«˜æ€§èƒ½æ¨¡ç³Šè™•ç†] ---
class BlurProcessor:
    @staticmethod
    def apply_blur(mask_tensor: torch.Tensor, radius: int) -> torch.Tensor:
        if radius <= 0: return mask_tensor
        if LAMA_CPP_AVAILABLE:
            return custom_cuda_blur.gaussian_blur(mask_tensor, radius)
        else:
            return BlurProcessor._pytorch_gaussian_blur(mask_tensor, radius)

    @staticmethod
    def _pytorch_gaussian_blur(tensor: torch.Tensor, radius: int) -> torch.Tensor:
        kernel_size = 2 * radius + 1
        sigma = radius / 3.0
        x = torch.arange(kernel_size, dtype=torch.float32, device=tensor.device) - kernel_size // 2
        gauss = torch.exp(-0.5 * (x / sigma) ** 2)
        gauss = gauss / gauss.sum()
        gauss = gauss.view(1, 1, 1, -1)
        padding = kernel_size // 2
        tensor = F.conv2d(tensor, gauss, padding=(0, padding), groups=tensor.shape[1])
        tensor = F.conv2d(tensor, gauss.transpose(-1, -2), padding=(padding, 0), groups=tensor.shape[1])
        return tensor


# --- [æ€§èƒ½ç›£æ§] ---
@contextmanager
def performance_monitor(operation_name: str):
    start_time = time.time()
    start_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
    try:
        yield
    finally:
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
        elapsed_time = end_time - start_time
        memory_delta = (end_memory - start_memory) / 1024 / 1024
        print(f"â±ï¸  {operation_name}: {elapsed_time:.3f}s, å…§å­˜è®ŠåŒ–: {memory_delta:+.1f}MB")


# --- [å„ªåŒ–çš„ä¸»ç¯€é»é¡] ---
class LamaRemover:
    """
    æ¥µé™å„ªåŒ–çš„ LaMa ç§»é™¤ç¯€é» (å‹•æ…‹å°ºå¯¸ç‰ˆ)
    ç‰¹é»ï¼š
    - å–®ä¾‹æ¨¡å‹ç®¡ç†ï¼Œé¿å…é‡è¤‡è¼‰å…¥
    - Padding ç­–ç•¥ï¼Œä¿æŒåœ–åƒé•·å¯¬æ¯”ï¼Œæå‡å“è³ª
    - Cropping å¾Œè™•ç†ï¼Œé‚„åŸåŸå§‹å°ºå¯¸
    - æ€§èƒ½ç›£æ§ï¼Œå¯¦æ™‚è¿½è¹¤æ•ˆèƒ½
    """

    def __init__(self):
        self.tensor_pool = None

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "masks": ("MASK",),
                "mask_threshold": ("INT", {"default": DEFAULT_MASK_THRESHOLD, "min": 0, "max": 255, "step": 1}),
                "gaussblur_radius": ("INT", {"default": DEFAULT_BLUR_RADIUS, "min": 0, "max": 50, "step": 1}),
                "invert_mask": ("BOOLEAN", {"default": False}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": MAX_BATCH_SIZE, "step": 1, "tooltip": "å°æ–¼å‹•æ…‹å°ºå¯¸, å»ºè­°è¨­ç‚º 1"}),
                "enable_performance_monitor": ("BOOLEAN", {"default": False, "tooltip": "å•Ÿç”¨æ€§èƒ½ç›£æ§ï¼ˆæœƒè¼•å¾®å½±éŸ¿æ€§èƒ½ï¼‰"}),
            },
        }

    CATEGORY = "LamaRemover"
    RETURN_NAMES = ("images",)
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "lama_remover"

    def _initialize_tensor_pool(self):
        if self.tensor_pool is None:
            self.tensor_pool = TensorPool(model_manager.device)

    def _normalize_tensorrt_output(self, tensor: torch.Tensor) -> torch.Tensor:
        # (æ­¤å‡½æ•¸ç„¡éœ€ä¿®æ”¹ï¼Œæ­¸ä¸€åŒ–é‚è¼¯ä¿æŒä¸è®Š)
        normalized_tensors = []
        for i in range(tensor.shape[0]):
            sample = tensor[i:i + 1]
            min_val, max_val = torch.min(sample), torch.max(sample)
            if max_val > min_val:
                normalized_sample = (sample - min_val) / (max_val - min_val)
            else:
                normalized_sample = torch.zeros_like(sample)
            normalized_sample = torch.clamp(normalized_sample, 0.0, 1.0)
            normalized_tensors.append(normalized_sample)
        return torch.cat(normalized_tensors, dim=0)

    def _validate_inputs(self, images: torch.Tensor, masks: torch.Tensor, is_image_mask: bool = False) -> bool:
        # (æ­¤å‡½æ•¸ç„¡éœ€ä¿®æ”¹ï¼Œé©—è­‰é‚è¼¯ä¿æŒä¸è®Š)
        if images.shape[0] != masks.shape[0]: return False
        if len(images.shape) != 4: return False
        if is_image_mask and len(masks.shape) != 4: return False
        if not is_image_mask and len(masks.shape) != 3: return False
        return True

    # --- NEW: Padding è¼”åŠ©å‡½æ•¸ ---
    def _pad_tensor(self, tensor: torch.Tensor) -> Tuple[torch.Tensor, Tuple[int, int, int, int]]:
        """
        å°‡å¼µé‡å¡«å……åˆ°é•·å¯¬å‡ç‚º PADDING_FACTOR çš„å€æ•¸
        è¿”å›å¡«å……å¾Œçš„å¼µé‡å’ŒåŸå§‹çš„å¡«å……é‚Šç•Œ
        """
        b, c, h, w = tensor.shape

        # è¨ˆç®—æ–°çš„ç›®æ¨™é•·å¯¬
        new_h = math.ceil(h / PADDING_FACTOR) * PADDING_FACTOR
        new_w = math.ceil(w / PADDING_FACTOR) * PADDING_FACTOR

        # è¨ˆç®—éœ€è¦å¡«å……çš„é‡ (å³é‚Šå’Œä¸‹é‚Š)
        pad_w = new_w - w
        pad_h = new_h - h

        # ä½¿ç”¨ F.pad é€²è¡Œå¡«å……
        # (pad_left, pad_right, pad_top, pad_bottom)
        padding = (0, pad_w, 0, pad_h)
        padded_tensor = F.pad(tensor, padding, "constant", 0)

        print(f"ğŸ–¼ï¸  Padding: åŸå§‹å°ºå¯¸ ({h}, {w}) -> å¡«å……å¾Œå°ºå¯¸ ({new_h}, {new_w})")

        return padded_tensor, (h, w)

    # --- REWRITTEN: è³‡æ–™æº–å‚™ï¼Œå¾ Resize æ”¹ç‚º Padding ---
    def _prepare_tensors(self, image: torch.Tensor, mask: torch.Tensor, is_image_mask: bool = False) -> Tuple[torch.Tensor, torch.Tensor, Tuple[int, int]]:
        """
        ç‚ºå–®å€‹åœ–åƒå’Œé®ç½©æº–å‚™å¼µé‡ï¼Œä½¿ç”¨ Padding ç­–ç•¥
        """
        device = model_manager.device

        # 1. è™•ç†åœ–åƒ
        image_tensor = image.permute(2, 0, 1).unsqueeze(0).to(device)  # HWC -> BCHW
        padded_image, original_shape = self._pad_tensor(image_tensor)

        # 2. è™•ç†é®ç½© (çµ±ä¸€æ ¼å¼)
        if is_image_mask:
            if mask.ndim == 3 and mask.shape[2] > 1:
                if mask.shape[2] >= 3:
                    mask = 0.299 * mask[:, :, 0] + 0.587 * mask[:, :, 1] + 0.114 * mask[:, :, 2]
                else:
                    mask = mask[:, :, 0]
            elif mask.ndim == 3 and mask.shape[2] == 1:
                mask = mask[:, :, 0]
        elif mask.ndim == 3:
            mask = mask[:, :, 0]

        mask_tensor = mask.unsqueeze(0).unsqueeze(0).to(device)  # HW -> BCHW

        # 3. å°‡é®ç½©ç¸®æ”¾ä¸¦å¡«å……åˆ°èˆ‡åœ–åƒç›¸åŒçš„å°ºå¯¸
        # é¦–å…ˆï¼Œå°‡é®ç½©ç¸®æ”¾è‡³åŸå§‹åœ–åƒå¤§å°ï¼ˆå¦‚æœå®ƒå€‘ä¸åŒ¹é…ï¼‰
        if (mask_tensor.shape[2], mask_tensor.shape[3]) != (original_shape[0], original_shape[1]):
            mask_tensor = transforms.functional.resize(
                mask_tensor,
                (original_shape[0], original_shape[1]),
                interpolation=transforms.InterpolationMode.NEAREST
            )
        # ç„¶å¾Œï¼Œä½¿ç”¨èˆ‡åœ–åƒå®Œå…¨ç›¸åŒçš„ Padding
        padded_mask, _ = self._pad_tensor(mask_tensor)

        return padded_image, padded_mask, original_shape

    # --- REWRITTEN: çµæœå¾Œè™•ç†ï¼Œå¾ Resize æ”¹ç‚º Cropping ---
    def _postprocess_result(self, result: torch.Tensor, original_shape: Tuple[int, int]) -> torch.Tensor:
        """
        å¾Œè™•ç†çµæœå¼µé‡ï¼Œä½¿ç”¨ Cropping ç­–ç•¥
        """
        h, w = original_shape

        # å¾å·¦ä¸Šè§’è£å‰ªå›åŸå§‹å°ºå¯¸
        cropped_result = result[:, :, :h, :w]

        # è½‰æ›ç‚º ComfyUI æ ¼å¼ (BCHW -> BHWC) å’Œ CPU
        result_comfy = cropped_result.permute(0, 2, 3, 1).cpu()

        return result_comfy

    def lama_remover(self, images: torch.Tensor, masks: torch.Tensor,
                     mask_threshold: int, gaussblur_radius: int, invert_mask: bool,
                     batch_size: int = 1, enable_performance_monitor: bool = False,
                     is_image_mask: bool = False):
        if not self._validate_inputs(images, masks, is_image_mask):
            return (images,)

        monitor = performance_monitor if enable_performance_monitor else lambda x: contextmanager(lambda: (yield))()

        with monitor("ç¸½è™•ç†æ™‚é–“"):
            all_results = []
            num_images = images.shape[0]

            # --- MODIFIED: ç°¡åŒ–è¿´åœˆä»¥é©æ‡‰å‹•æ…‹å°ºå¯¸ ---
            # å‹•æ…‹å°ºå¯¸ä½¿å¾—æ‰¹æ¬¡å…§å°ºå¯¸çµ±ä¸€è®Šå¾—å¾ˆè¤‡é›œï¼Œé€å¼µè™•ç†æ˜¯æœ€ç©©å®šå¯é çš„æ–¹å¼ã€‚
            # åŸæœ‰çš„ batch_size åƒæ•¸ä¿ç•™ï¼Œä½†å…§éƒ¨é‚è¼¯ä»¥å–®å¼µè™•ç†ç‚ºä¸»ã€‚
            for i in range(num_images):
                with monitor(f"åœ–åƒ {i + 1}/{num_images}"):
                    try:
                        image = images[i:i + 1]  # å–å–®å¼µåœ–
                        mask = masks[i:i + 1]  # å–å°æ‡‰é®ç½©

                        # æº–å‚™æ•¸æ“š (Padding)
                        with monitor("æ•¸æ“šæº–å‚™ (Padding)"):
                            # æ³¨æ„ï¼šis_image_mask åˆ¤æ–·éœ€è¦åŸå§‹çš„å¼µé‡ç¶­åº¦
                            is_img_mask_flag = is_image_mask and len(masks.shape) == 4
                            padded_image, padded_mask, original_shape = self._prepare_tensors(image[0], mask[0], is_img_mask_flag)

                        # é®ç½©é è™•ç†
                        with monitor("é®ç½©è™•ç†"):
                            if invert_mask:
                                padded_mask = 1.0 - padded_mask
                            if gaussblur_radius > 0:
                                padded_mask = BlurProcessor.apply_blur(padded_mask, gaussblur_radius)
                            threshold = mask_threshold / 255.0
                            padded_mask = (padded_mask > threshold).float()

                        # æ¨¡å‹æ¨ç†
                        with monitor("TensorRT æ¨ç†"):
                            with torch.no_grad():
                                batch_results = model_manager.model(padded_image, padded_mask)
                                torch.cuda.synchronize()

                        # çµæœå¾Œè™•ç†
                        with monitor("çµæœå¾Œè™•ç† (Cropping & Normalize)"):
                            normalized_results = self._normalize_tensorrt_output(batch_results)
                            processed = self._postprocess_result(normalized_results, original_shape)
                            all_results.append(processed)

                    except Exception as e:
                        print(f"âŒ åœ–åƒ {i + 1} è™•ç†å¤±æ•—: {e}")
                        import traceback
                        traceback.print_exc()
                        # å‚™æ´ï¼šè¿”å›åŸå§‹åœ–åƒ
                        all_results.append(images[i:i + 1])

                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

        try:
            final_result = torch.cat(all_results, dim=0)
        except Exception as e:
            print(f"âŒ çµæœåˆä½µå¤±æ•—: {e}")
            final_result = images

        if enable_performance_monitor:
            print(f"ğŸ§¹ æœ€çµ‚ GPU å…§å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024 / 1024:.1f}MB")

        return (final_result,)


class LamaRemoverIMG(LamaRemover):
    @classmethod
    def INPUT_TYPES(cls):
        base_inputs = super().INPUT_TYPES()
        base_inputs["required"]["masks"] = ("IMAGE",)
        return base_inputs

    FUNCTION = "lama_remover_img"

    def lama_remover_img(self, images: torch.Tensor, masks: torch.Tensor,
                         mask_threshold: int, gaussblur_radius: int, invert_mask: bool,
                         batch_size: int = 1, enable_performance_monitor: bool = False):
        return self.lama_remover(
            images=images,
            masks=masks,
            mask_threshold=mask_threshold,
            gaussblur_radius=gaussblur_radius,
            invert_mask=invert_mask,
            batch_size=batch_size,
            enable_performance_monitor=enable_performance_monitor,
            is_image_mask=True
        )


def get_model_info():
    try:
        return model_manager.model.get_engine_info()
    except Exception as e:
        return {"error": str(e)}


def cleanup_resources():
    if torch.cuda.is_available(): torch.cuda.empty_cache()
    gc.collect()
    print("ğŸ§¹ è³‡æºæ¸…ç†å®Œæˆ")


# --- ComfyUI ç¯€é»è¨»å†Š (MODIFIED) ---
NODE_CLASS_MAPPINGS = {
    "LamaRemover": LamaRemover,
    "LamaRemoverIMG": LamaRemoverIMG
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LamaRemover": "ğŸš€ Big Lama Remover (å‹•æ…‹å°ºå¯¸ç‰ˆ)",
    "LamaRemoverIMG": "ğŸš€ Big Lama Remover IMG (å‹•æ…‹å°ºå¯¸ç‰ˆ)"
}