# /nodes/remover.py (æœ€çµ‚å®Œæ•´å„ªåŒ–ç‰ˆï¼šTensorRT + å‹•æ…‹å°ºå¯¸ + torch.compile)

import torch
import torch.nn.functional as F
from torchvision import transforms
import time
import gc
from typing import Tuple, List
from contextlib import contextmanager
import math

# æª¢æŸ¥ä¸¦è™•ç† torch.compile çš„å¯ç”¨æ€§
if not hasattr(torch, 'compile'):
    print("âš ï¸  è­¦å‘Š: æ‚¨çš„ PyTorch ç‰ˆæœ¬éä½ï¼Œä¸æ”¯æ´ torch.compileã€‚å»ºè­°å‡ç´šè‡³ 2.0 æˆ–æ›´é«˜ç‰ˆæœ¬ä»¥ç²å¾—æœ€ä½³æ€§èƒ½ã€‚")


    # å®šç¾©ä¸€å€‹å‡çš„è£é£¾å™¨ä»¥ç¢ºä¿ç¨‹å¼ç¢¼åœ¨èˆŠç‰ˆæœ¬ä¸Šä¹Ÿèƒ½é‹è¡Œï¼Œä½†æ²’æœ‰æ€§èƒ½æå‡
    def torch_compile_stub(fn, *args, **kwargs):
        return fn


    torch.compile = torch_compile_stub

# å¾æˆ‘å€‘è‡ªæœ‰çš„ lama å¥—ä»¶ä¸­åŒ¯å…¥æ¨¡å‹å®šç¾©
from ..lama import model

# --- å¸¸é‡å®šç¾© ---
PADDING_FACTOR = 32  # ç‚ºäº†æ•¸å€¼ç©©å®šæ€§ï¼Œä½¿ç”¨è¼ƒä¿å®ˆçš„ 32 å€å¡«å……
DEFAULT_MASK_THRESHOLD = 6
DEFAULT_BLUR_RADIUS = 1
MAX_BATCH_SIZE = 1  # å°æ–¼å‹•æ…‹å°ºå¯¸ï¼Œå»ºè­°æ‰¹æ¬¡ç‚º 1 ä»¥ç°¡åŒ–å…§å­˜ç®¡ç†

# --- [æ¥µé™æ•ˆèƒ½èåˆ] ---
try:
    from lama_cpp import _C as custom_cuda_blur

    LAMA_CPP_AVAILABLE = True
    print("âœ… æˆåŠŸåŒ¯å…¥è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚")
except ImportError:
    LAMA_CPP_AVAILABLE = False
    print("âš ï¸  æœªæ‰¾åˆ°è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒï¼Œå°‡ä½¿ç”¨ PyTorch åŸç”Ÿæ¨¡ç³Šè™•ç†ã€‚")


# --- [å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨] ---
class LamaModelManager:
    """å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨ï¼Œé¿å…é‡è¤‡è¼‰å…¥ TensorRT å¼•æ“"""
    _instance = None
    _model = None
    _device = None
    _is_initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LamaModelManager, cls).__new__(cls)
        return cls._instance

    @property
    def model(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._model

    @property
    def device(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._device

    def _initialize_model(self):
        if self._is_initialized:
            return
        print("ğŸ”„ åˆå§‹åŒ– LaMa TensorRT æ¨¡å‹...")
        start_time = time.time()
        try:
            self._model = model.BigLama()
            self._device = self._model.device
            self._warmup_model(512, 512)
            init_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚: {init_time:.2f}s")
            self._is_initialized = True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _warmup_model(self, height, width):
        print(f"ğŸ”¥ åŸ·è¡Œæ¨¡å‹é ç†± (å°ºå¯¸: {height}x{width})...")
        try:
            dummy_image = torch.randn(1, 3, height, width, device=self._device, dtype=torch.float32)
            dummy_mask = torch.randn(1, 1, height, width, device=self._device, dtype=torch.float32)
            for _ in range(3):
                with torch.no_grad():
                    _ = self._model(dummy_image, dummy_mask)
                    if torch.cuda.is_available():
                        torch.cuda.synchronize()
            print("âœ… æ¨¡å‹é ç†±å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹é ç†±å¤±æ•—: {e}")


model_manager = LamaModelManager()


# --- [é«˜æ€§èƒ½æ¨¡ç³Šè™•ç†] ---
class BlurProcessor:
    # ç‚ºäº† JIT ç·¨è­¯ï¼Œå°‡å…¶ç§»å‡º LamaRemover é¡åˆ¥ï¼Œä½¿å…¶æˆç‚ºå¯è¢«ç·¨è­¯çš„ç¨ç«‹å‡½æ•¸
    @staticmethod
    @torch.compile(mode="reduce-overhead")
    def _pytorch_gaussian_blur(tensor: torch.Tensor, radius: int) -> torch.Tensor:
        kernel_size = 2 * radius + 1
        sigma = radius / 3.0
        x = torch.arange(kernel_size, dtype=torch.float32, device=tensor.device) - kernel_size // 2
        gauss = torch.exp(-0.5 * (x / sigma) ** 2)
        gauss = gauss / gauss.sum()
        gauss = gauss.view(1, 1, 1, -1)
        padding = kernel_size // 2
        tensor = F.conv2d(tensor, gauss, padding=(0, padding), groups=tensor.shape[1])
        tensor = F.conv2d(tensor, gauss.transpose(-1, -2), padding=(padding, 0), groups=tensor.shape[1])
        return tensor

    @staticmethod
    def apply_blur(mask_tensor: torch.Tensor, radius: int) -> torch.Tensor:
        if radius <= 0: return mask_tensor
        if LAMA_CPP_AVAILABLE:
            return custom_cuda_blur.gaussian_blur(mask_tensor, radius)
        else:
            return BlurProcessor._pytorch_gaussian_blur(mask_tensor, radius)


# --- [æ€§èƒ½ç›£æ§] ---
@contextmanager
def performance_monitor(operation_name: str):
    start_time = time.time()
    start_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
    try:
        yield
    finally:
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
        elapsed_time = end_time - start_time
        memory_delta = (end_memory - start_memory) / 1024 / 1024
        print(f"â±ï¸  {operation_name}: {elapsed_time:.3f}s, å…§å­˜è®ŠåŒ–: {memory_delta:+.1f}MB")


# --- [å„ªåŒ–çš„ä¸»ç¯€é»é¡] ---
class LamaRemover:
    """
    æ¥µé™å„ªåŒ–çš„ LaMa ç§»é™¤ç¯€é» (å‹•æ…‹å°ºå¯¸ + JIT å„ªåŒ–ç‰ˆ)
    ç‰¹é»ï¼š
    - å–®ä¾‹æ¨¡å‹ç®¡ç†ï¼Œé¿å…é‡è¤‡è¼‰å…¥
    - Padding ç­–ç•¥ï¼Œä¿æŒåœ–åƒé•·å¯¬æ¯”ï¼Œæå‡å“è³ª
    - torch.compile JIT ç·¨è­¯å™¨ï¼ŒåŠ é€Ÿå‰å¾Œè™•ç†
    - å‘é‡åŒ–æ“ä½œï¼Œæå‡è¨ˆç®—æ•ˆç‡
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "masks": ("MASK",),
                "mask_threshold": ("INT", {"default": DEFAULT_MASK_THRESHOLD, "min": 0, "max": 255, "step": 1}),
                "gaussblur_radius": ("INT", {"default": DEFAULT_BLUR_RADIUS, "min": 0, "max": 50, "step": 1}),
                "invert_mask": ("BOOLEAN", {"default": False}),
                "enable_performance_monitor": ("BOOLEAN", {"default": False, "tooltip": "å•Ÿç”¨æ€§èƒ½ç›£æ§ï¼ˆæœƒè¼•å¾®å½±éŸ¿æ€§èƒ½ï¼‰"}),
            },
        }

    CATEGORY = "LamaRemover"
    RETURN_NAMES = ("images",)
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "lama_remover"

    @staticmethod
    @torch.compile(mode="reduce-overhead", fullgraph=True)
    def _normalize_tensorrt_output(tensor: torch.Tensor) -> torch.Tensor:
        """å‘é‡åŒ–ä¸¦ JIT ç·¨è­¯çš„æ­£è¦åŒ–å‡½æ•¸"""
        min_val = torch.amin(tensor, dim=(1, 2, 3), keepdim=True)
        max_val = torch.amax(tensor, dim=(1, 2, 3), keepdim=True)
        delta = max_val - min_val + 1e-6
        normalized_tensor = (tensor - min_val) / delta
        is_flat = (max_val - min_val) < 1e-5
        normalized_tensor[is_flat] = 0
        return torch.clamp(normalized_tensor, 0.0, 1.0)

    @staticmethod
    @torch.compile(mode="reduce-overhead")
    def _pad_tensor(tensor: torch.Tensor) -> Tuple[torch.Tensor, Tuple[int, int]]:
        """å°‡å¼µé‡å¡«å……åˆ°é•·å¯¬å‡ç‚º PADDING_FACTOR çš„å€æ•¸"""
        b, c, h, w = tensor.shape
        new_h = math.ceil(h / PADDING_FACTOR) * PADDING_FACTOR
        new_w = math.ceil(w / PADDING_FACTOR) * PADDING_FACTOR
        pad_w = new_w - w
        pad_h = new_h - h
        padding = (0, pad_w, 0, pad_h)
        return F.pad(tensor, padding, "constant", 0), (h, w)

    def _prepare_tensors(self, image: torch.Tensor, mask: torch.Tensor, is_image_mask: bool = False) -> Tuple[torch.Tensor, torch.Tensor, Tuple[int, int]]:
        device = model_manager.device
        image_tensor = image.permute(2, 0, 1).unsqueeze(0).to(device)
        padded_image, original_shape = self._pad_tensor(image_tensor)

        if is_image_mask:
            if mask.ndim == 3:
                if mask.shape[2] >= 3:
                    mask = 0.299 * mask[:, :, 0] + 0.587 * mask[:, :, 1] + 0.114 * mask[:, :, 2]
                else:  # Grayscale or other single-channel image
                    mask = mask[:, :, 0]
        elif mask.ndim == 3:
            mask = mask[:, :, 0]

        mask_tensor = mask.unsqueeze(0).unsqueeze(0).to(device)

        if (mask_tensor.shape[2], mask_tensor.shape[3]) != (original_shape[0], original_shape[1]):
            mask_tensor = F.interpolate(mask_tensor, size=original_shape, mode='nearest')

        padded_mask, _ = self._pad_tensor(mask_tensor)
        return padded_image, padded_mask, original_shape

    @staticmethod
    @torch.compile(mode="reduce-overhead", fullgraph=True)
    def _postprocess_result(result: torch.Tensor, original_shape: Tuple[int, int]) -> torch.Tensor:
        """JIT ç·¨è­¯çš„å¾Œè™•ç†å‡½æ•¸ï¼Œä½¿ç”¨ Cropping ç­–ç•¥"""
        h, w = original_shape
        cropped_result = result[:, :, :h, :w]
        return cropped_result.permute(0, 2, 3, 1).cpu()

    def lama_remover(self, images: torch.Tensor, masks: torch.Tensor,
                     mask_threshold: int, gaussblur_radius: int, invert_mask: bool,
                     enable_performance_monitor: bool = False,
                     is_image_mask: bool = False):

        monitor = performance_monitor if enable_performance_monitor else lambda x: contextmanager(lambda: (yield))()

        with monitor("ç¸½è™•ç†æ™‚é–“"):
            all_results = []
            num_images = images.shape[0]

            for i in range(num_images):
                with monitor(f"åœ–åƒ {i + 1}/{num_images}"):
                    try:
                        image = images[i]
                        mask = masks[i]

                        with monitor("æ•¸æ“šæº–å‚™ (Padding)"):
                            padded_image, padded_mask, original_shape = self._prepare_tensors(image, mask, is_image_mask)

                        with monitor("é®ç½©è™•ç†"):
                            if invert_mask: padded_mask = 1.0 - padded_mask
                            if gaussblur_radius > 0: padded_mask = BlurProcessor.apply_blur(padded_mask, gaussblur_radius)
                            threshold = mask_threshold / 255.0
                            padded_mask = (padded_mask > threshold).float()

                        with monitor("TensorRT æ¨ç†"):
                            with torch.no_grad():
                                batch_results = model_manager.model(padded_image, padded_mask)
                                if torch.cuda.is_available(): torch.cuda.synchronize()

                        with monitor("çµæœå¾Œè™•ç† (Cropping & Normalize)"):
                            normalized_results = self._normalize_tensorrt_output(batch_results)
                            processed = self._postprocess_result(normalized_results, original_shape)
                            all_results.append(processed)

                    except Exception as e:
                        print(f"âŒ åœ–åƒ {i + 1} è™•ç†å¤±æ•—: {e}")
                        import traceback
                        traceback.print_exc()
                        all_results.append(images[i:i + 1])

                    if torch.cuda.is_available(): torch.cuda.empty_cache()

        try:
            final_result = torch.cat(all_results, dim=0)
        except Exception as e:
            print(f"âŒ çµæœåˆä½µå¤±æ•—: {e}")
            final_result = images

        if enable_performance_monitor:
            print(f"ğŸ§¹ æœ€çµ‚ GPU å…§å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024 / 1024:.1f}MB")

        return (final_result,)


class LamaRemoverIMG(LamaRemover):
    @classmethod
    def INPUT_TYPES(cls):
        base_inputs = super().INPUT_TYPES()
        base_inputs["required"]["masks"] = ("IMAGE",)
        return base_inputs

    FUNCTION = "lama_remover_img"

    def lama_remover_img(self, **kwargs):
        return self.lama_remover(is_image_mask=True, **kwargs)


# --- ComfyUI ç¯€é»è¨»å†Š ---
NODE_CLASS_MAPPINGS = {
    "LamaRemover": LamaRemover,
    "LamaRemoverIMG": LamaRemoverIMG
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LamaRemover": "ğŸš€ Big Lama Remover (JIT å„ªåŒ–ç‰ˆ)",
    "LamaRemoverIMG": "ğŸš€ Big Lama Remover IMG (JIT å„ªåŒ–ç‰ˆ)"
}