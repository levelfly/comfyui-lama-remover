# /nodes/remover.py (æ¥µé™å„ªåŒ–ç‰ˆæœ¬ï¼šå–®ä¾‹æ¨¡å‹ + æ‰¹è™•ç† + å…§å­˜æ±  + æ€§èƒ½ç›£æ§)

import torch
import torch.nn.functional as F
from torchvision import transforms
import time
import gc
from typing import Tuple, Optional, List
from contextlib import contextmanager

# å¾æˆ‘å€‘è‡ªæœ‰çš„ lama å¥—ä»¶ä¸­åŒ¯å…¥æ¨¡å‹å®šç¾©
from ..lama import model

# --- å¸¸é‡å®šç¾© ---
MODEL_INPUT_SIZE = 512  # LaMa æ¨¡å‹çš„æ¨™æº–è¼¸å…¥å°ºå¯¸
DEFAULT_MASK_THRESHOLD = 128
DEFAULT_BLUR_RADIUS = 10
MAX_BATCH_SIZE = 4  # RTX 3090 çš„æœ€ä½³æ‰¹è™•ç†å¤§å°

# --- [æ¥µé™æ•ˆèƒ½èåˆ] ---
try:
    from lama_cpp import _C as custom_cuda_blur

    LAMA_CPP_AVAILABLE = True
    print("âœ… æˆåŠŸåŒ¯å…¥è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚å·²å•Ÿç”¨æ¥µé™æ•ˆèƒ½æ¨¡å¼ã€‚")
except ImportError:
    LAMA_CPP_AVAILABLE = False
    print("âš ï¸  æœªæ‰¾åˆ°è‡ªè¨‚ CUDA æ¨¡ç³Šæ ¸å¿ƒã€‚å°‡ä½¿ç”¨ PyTorch åŸç”Ÿæ¨¡ç³Šè™•ç†ã€‚")
    from PIL import ImageFilter


# --- [å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨] ---
class LamaModelManager:
    """
    å…¨å±€å–®ä¾‹æ¨¡å‹ç®¡ç†å™¨ï¼Œé¿å…é‡è¤‡è¼‰å…¥ TensorRT å¼•æ“
    """
    _instance = None
    _model = None
    _device = None
    _is_initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(LamaModelManager, cls).__new__(cls)
        return cls._instance

    @property
    def model(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._model

    @property
    def device(self):
        if not self._is_initialized:
            self._initialize_model()
        return self._device

    def _initialize_model(self):
        """æƒ°æ€§åˆå§‹åŒ–æ¨¡å‹"""
        if self._is_initialized:
            return

        print("ğŸ”„ åˆå§‹åŒ– LaMa TensorRT æ¨¡å‹...")
        start_time = time.time()

        try:
            self._model = model.BigLama()
            self._device = self._model.device

            # é ç†±æ¨¡å‹ä»¥å„ªåŒ–é¦–æ¬¡æ¨ç†é€Ÿåº¦
            self._warmup_model()

            init_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚: {init_time:.2f}s")

            self._is_initialized = True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _warmup_model(self):
        """é ç†±æ¨¡å‹ä»¥å„ªåŒ–é¦–æ¬¡æ¨ç†"""
        print("ğŸ”¥ åŸ·è¡Œæ¨¡å‹é ç†±...")
        try:
            # å‰µå»ºè™›æ“¬è¼¸å…¥é€²è¡Œé ç†±
            dummy_image = torch.randn(1, 3, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE,
                                      device=self._model.device, dtype=torch.float32)
            dummy_mask = torch.randn(1, 1, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE,
                                     device=self._model.device, dtype=torch.float32)

            # åŸ·è¡Œå¹¾æ¬¡é ç†±æ¨ç†
            for _ in range(3):
                with torch.no_grad():
                    _ = self._model(dummy_image, dummy_mask)
                    torch.cuda.synchronize()

            print("âœ… æ¨¡å‹é ç†±å®Œæˆ")

        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹é ç†±å¤±æ•—: {e}")


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å¯¦ä¾‹
model_manager = LamaModelManager()


# --- [åœ–åƒè®Šæ›è¨˜éŒ„] ---
class ImageTransformInfo:
    """è¨˜éŒ„åœ–åƒè®Šæ›ä¿¡æ¯ï¼Œç”¨æ–¼ç²¾ç¢ºçš„å¡«å……èˆ‡è£åˆ‡"""

    def __init__(self, original_h: int, original_w: int,
                 scaled_h: int, scaled_w: int,
                 x_offset: int, y_offset: int):
        self.original_h = original_h
        self.original_w = original_w
        self.scaled_h = scaled_h
        self.scaled_w = scaled_w
        self.x_offset = x_offset
        self.y_offset = y_offset


# --- [é«˜å“è³ªåœ–åƒè™•ç†å™¨] ---
class HighQualityImageProcessor:
    """
    å°ˆæ¥­ç´šåœ–åƒè™•ç†å™¨ï¼Œå¯¦ç¾ä¿æŒé•·å¯¬æ¯”çš„å¡«å……èˆ‡è£åˆ‡
    """

    @staticmethod
    def get_interpolation_mode(mode_str: str):
        """ç²å–æ’å€¼æ¨¡å¼"""
        if mode_str == "BICUBIC":
            return transforms.InterpolationMode.BICUBIC
        else:
            return transforms.InterpolationMode.BILINEAR

    @staticmethod
    def pad_to_square(image: torch.Tensor, target_size: int = MODEL_INPUT_SIZE,
                      interpolation_mode=transforms.InterpolationMode.BICUBIC) -> Tuple[torch.Tensor, ImageTransformInfo]:
        """
        å°‡åœ–åƒå¡«å……ç‚ºæ­£æ–¹å½¢ï¼Œä¿æŒé•·å¯¬æ¯”
        è¿”å›ï¼š(å¡«å……å¾Œçš„åœ–åƒ, è®Šæ›ä¿¡æ¯)
        """
        # è¼¸å…¥: (C, H, W)
        _, original_h, original_w = image.shape

        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼Œä½¿æœ€é•·é‚Šç­‰æ–¼target_size
        scale = target_size / max(original_h, original_w)
        scaled_h = int(original_h * scale)
        scaled_w = int(original_w * scale)

        # ç¸®æ”¾åœ–åƒï¼Œä¿æŒé•·å¯¬æ¯”
        image_scaled = transforms.functional.resize(
            image.unsqueeze(0), (scaled_h, scaled_w),
            interpolation=interpolation_mode,
            antialias=True
        ).squeeze(0)

        # è¨ˆç®—å¡«å……ä½ç½®ï¼ˆå±…ä¸­ï¼‰
        x_offset = (target_size - scaled_w) // 2
        y_offset = (target_size - scaled_h) // 2

        # å‰µå»ºé»‘è‰²èƒŒæ™¯ä¸¦å¡«å……
        padded_image = torch.zeros(image.shape[0], target_size, target_size,
                                   dtype=image.dtype, device=image.device)
        padded_image[:, y_offset:y_offset + scaled_h, x_offset:x_offset + scaled_w] = image_scaled

        # è¨˜éŒ„è®Šæ›ä¿¡æ¯
        transform_info = ImageTransformInfo(
            original_h, original_w, scaled_h, scaled_w, x_offset, y_offset
        )

        return padded_image, transform_info

    @staticmethod
    def crop_and_restore(result: torch.Tensor, transform_info: ImageTransformInfo,
                         interpolation_mode=transforms.InterpolationMode.BICUBIC) -> torch.Tensor:
        """
        å¾çµæœä¸­è£åˆ‡å‡ºæœ‰æ•ˆå€åŸŸä¸¦æ¢å¾©åˆ°åŸå§‹å°ºå¯¸
        """
        # è¼¸å…¥: (C, H, W) æˆ– (1, C, H, W)
        if result.dim() == 4:
            result = result.squeeze(0)  # ç§»é™¤batchç¶­åº¦

        # è£åˆ‡å‡ºæœ‰æ•ˆå€åŸŸ
        y_start = transform_info.y_offset
        y_end = transform_info.y_offset + transform_info.scaled_h
        x_start = transform_info.x_offset
        x_end = transform_info.x_offset + transform_info.scaled_w

        cropped = result[:, y_start:y_end, x_start:x_end]

        # ç¸®æ”¾å›åŸå§‹å°ºå¯¸
        restored = transforms.functional.resize(
            cropped.unsqueeze(0),
            (transform_info.original_h, transform_info.original_w),
            interpolation=interpolation_mode,
            antialias=True
        ).squeeze(0)

        return restored


class TensorPool:
    """
    å¼µé‡å…§å­˜æ± ï¼Œé‡ç”¨å¼µé‡ä»¥æ¸›å°‘å…§å­˜åˆ†é…é–‹éŠ·
    """

    def __init__(self, device):
        self.device = device
        self.pools = {}  # æŒ‰å½¢ç‹€åˆ†çµ„çš„å¼µé‡æ± 

    def get_tensor(self, shape, dtype=torch.float32):
        """ç²å–æŒ‡å®šå½¢ç‹€çš„å¼µé‡"""
        key = (tuple(shape), dtype)

        if key not in self.pools:
            self.pools[key] = []

        pool = self.pools[key]

        if pool:
            tensor = pool.pop()
            tensor.zero_()  # æ¸…é›¶é‡ç”¨
            return tensor
        else:
            return torch.zeros(shape, dtype=dtype, device=self.device)

    def return_tensor(self, tensor):
        """æ­¸é‚„å¼µé‡åˆ°æ± ä¸­"""
        key = (tuple(tensor.shape), tensor.dtype)

        if key not in self.pools:
            self.pools[key] = []

        # é™åˆ¶æ± å¤§å°é¿å…å…§å­˜æ´©æ¼
        if len(self.pools[key]) < 10:
            self.pools[key].append(tensor.detach())


# --- [é«˜æ€§èƒ½æ¨¡ç³Šè™•ç†] ---
class BlurProcessor:
    """
    é«˜æ€§èƒ½æ¨¡ç³Šè™•ç†å™¨ï¼Œæ”¯æŒæ‰¹è™•ç†å’Œ CUDA åŠ é€Ÿ
    """

    @staticmethod
    def apply_blur(mask_tensor: torch.Tensor, radius: int) -> torch.Tensor:
        """
        æ‡‰ç”¨é«˜æ–¯æ¨¡ç³Šï¼Œè‡ªå‹•é¸æ“‡æœ€ä½³å¯¦ç¾
        """
        if radius <= 0:
            return mask_tensor

        if LAMA_CPP_AVAILABLE:
            # ä½¿ç”¨è‡ªå®šç¾© CUDA æ ¸å¿ƒï¼ˆæœ€å¿«ï¼‰
            return custom_cuda_blur.gaussian_blur(mask_tensor, radius)
        else:
            # ä½¿ç”¨ PyTorch åŸç”Ÿå¯¦ç¾ï¼ˆè¼ƒå¿«ï¼‰
            return BlurProcessor._pytorch_gaussian_blur(mask_tensor, radius)

    @staticmethod
    def _pytorch_gaussian_blur(tensor: torch.Tensor, radius: int) -> torch.Tensor:
        """
        ä½¿ç”¨ PyTorch å¯¦ç¾çš„æ‰¹è™•ç†é«˜æ–¯æ¨¡ç³Š
        """
        # è¨ˆç®—é«˜æ–¯æ ¸å¤§å°
        kernel_size = 2 * radius + 1

        # å‰µå»ºé«˜æ–¯æ ¸
        sigma = radius / 3.0
        x = torch.arange(kernel_size, dtype=torch.float32, device=tensor.device)
        x = x - kernel_size // 2
        gauss = torch.exp(-0.5 * (x / sigma) ** 2)
        gauss = gauss / gauss.sum()

        # é‡å¡‘ç‚º 2D æ ¸
        gauss = gauss.view(1, 1, 1, -1)

        # æ‡‰ç”¨å¯åˆ†é›¢çš„é«˜æ–¯æ¨¡ç³Šï¼ˆæ°´å¹³ + å‚ç›´ï¼‰
        # æ°´å¹³æ¨¡ç³Š
        padding = kernel_size // 2
        tensor = F.conv2d(tensor, gauss, padding=(0, padding), groups=tensor.shape[1])
        # å‚ç›´æ¨¡ç³Š
        tensor = F.conv2d(tensor, gauss.transpose(-1, -2), padding=(padding, 0), groups=tensor.shape[1])

        return tensor


# --- [æ€§èƒ½ç›£æ§] ---
@contextmanager
def performance_monitor(operation_name: str):
    """æ€§èƒ½ç›£æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_time = time.time()
    start_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0

    try:
        yield
    finally:
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0

        elapsed_time = end_time - start_time
        memory_delta = (end_memory - start_memory) / 1024 / 1024  # MB

        print(f"â±ï¸  {operation_name}: {elapsed_time:.3f}s, å…§å­˜è®ŠåŒ–: {memory_delta:+.1f}MB")


# --- [å„ªåŒ–çš„ä¸»ç¯€é»é¡] ---
class LamaRemover:
    """
    æ¥µé™å„ªåŒ–çš„ LaMa ç§»é™¤ç¯€é»
    ç‰¹é»ï¼š
    - å–®ä¾‹æ¨¡å‹ç®¡ç†ï¼Œé¿å…é‡è¤‡è¼‰å…¥
    - æ™ºèƒ½æ‰¹è™•ç†ï¼Œå……åˆ†åˆ©ç”¨ RTX 3090
    - å…§å­˜æ± ç®¡ç†ï¼Œæ¸›å°‘åˆ†é…é–‹éŠ·
    - æ€§èƒ½ç›£æ§ï¼Œå¯¦æ™‚è¿½è¹¤æ•ˆèƒ½
    """

    def __init__(self):
        self.tensor_pool = None  # æƒ°æ€§åˆå§‹åŒ–

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "masks": ("MASK",),
                "mask_threshold": ("INT", {
                    "default": DEFAULT_MASK_THRESHOLD,
                    "min": 0, "max": 255, "step": 1
                }),
                "gaussblur_radius": ("INT", {
                    "default": DEFAULT_BLUR_RADIUS,
                    "min": 0, "max": 50, "step": 1
                }),
                "invert_mask": ("BOOLEAN", {"default": False}),
                "batch_size": ("INT", {
                    "default": 1, "min": 1, "max": MAX_BATCH_SIZE, "step": 1,
                    "tooltip": "æ‰¹è™•ç†å¤§å°ï¼ŒRTX 3090 å»ºè­° 2-4"
                }),
                "enable_performance_monitor": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å•Ÿç”¨æ€§èƒ½ç›£æ§ï¼ˆæœƒè¼•å¾®å½±éŸ¿æ€§èƒ½ï¼‰"
                }),
                "aggressive_normalization": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å•Ÿç”¨æ¿€é€²æ­£è¦åŒ–ï¼ˆåƒ…åœ¨è¼¸å‡ºéæš—/éæ›æ™‚ä½¿ç”¨ï¼‰"
                }),
                "interpolation_mode": (["BICUBIC", "BILINEAR"], {
                    "default": "BICUBIC",
                    "tooltip": "æ’å€¼æ¼”ç®—æ³•ï¼šBICUBICå“è³ªæ›´ä½³ï¼ŒBILINEARé€Ÿåº¦æ›´å¿«"
                }),
            },
        }

    CATEGORY = "LamaRemover"
    RETURN_NAMES = ("images",)
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "lama_remover"

    def _initialize_tensor_pool(self):
        """æƒ°æ€§åˆå§‹åŒ–å¼µé‡æ± """
        if self.tensor_pool is None:
            self.tensor_pool = TensorPool(model_manager.device)

    def _normalize_tensorrt_output(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        æ­£ç¢ºæ­¸ä¸€åŒ– TensorRT è¼¸å‡ºï¼Œç¶­æŒåŸç‰ˆé‚è¼¯é¿å…éæ›
        TensorRT çš„è¼¸å‡ºç¯„åœå¯èƒ½ä¸æ˜¯æ¨™æº–çš„ [0, 1]ï¼Œéœ€è¦å…ˆåš min-max æ­¸ä¸€åŒ–
        """
        # å°æ¯å€‹æ¨£æœ¬åˆ†åˆ¥é€²è¡Œæ­¸ä¸€åŒ–ï¼ˆæ‰¹è™•ç†ç‰ˆæœ¬ï¼‰
        normalized_tensors = []

        for i in range(tensor.shape[0]):
            sample = tensor[i:i + 1]  # ä¿æŒç¶­åº¦ (1, C, H, W)

            # ç²å–ç•¶å‰æ¨£æœ¬çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
            min_val = torch.min(sample)
            max_val = torch.max(sample)

            # èª¿è©¦ä¿¡æ¯ï¼šé¡¯ç¤º TensorRT åŸå§‹è¼¸å‡ºç¯„åœ
            print(f"ğŸ” æ¨£æœ¬ {i + 1} TensorRT åŸå§‹è¼¸å‡ºç¯„åœ: [{min_val.item():.4f}, {max_val.item():.4f}]")

            # é¿å…é™¤é›¶éŒ¯èª¤ï¼šåªæœ‰ç•¶ max > min æ™‚æ‰é€²è¡Œæ­¸ä¸€åŒ–
            if max_val > min_val:
                # min-max æ­¸ä¸€åŒ–ï¼šå°‡ [min, max] æ˜ å°„åˆ° [0, 1]
                normalized_sample = (sample - min_val) / (max_val - min_val)
                print(f"âœ… æ¨£æœ¬ {i + 1} æ­¸ä¸€åŒ–å¾Œç¯„åœ: [0.0000, 1.0000]")
            else:
                # å¦‚æœ min == maxï¼Œç›´æ¥è¨­ç‚º 0ï¼ˆé¿å… NaNï¼‰
                normalized_sample = torch.zeros_like(sample)
                print(f"âš ï¸  æ¨£æœ¬ {i + 1} min==maxï¼Œè¨­ç‚ºé›¶å€¼")

            # æœ€çµ‚ clamp ç¢ºä¿åš´æ ¼åœ¨ [0, 1] ç¯„åœå…§
            normalized_sample = torch.clamp(normalized_sample, 0.0, 1.0)
            normalized_tensors.append(normalized_sample)

        # åˆä½µæ‰€æœ‰æ­¸ä¸€åŒ–å¾Œçš„æ¨£æœ¬
        return torch.cat(normalized_tensors, dim=0)

    def _validate_inputs(self, images: torch.Tensor, masks: torch.Tensor, is_image_mask: bool = False) -> bool:
        """é©—è­‰è¼¸å…¥å¼µé‡"""
        if images.shape[0] != masks.shape[0]:
            print(f"âŒ åœ–åƒå’Œé®ç½©çš„æ‰¹æ¬¡å¤§å°ä¸åŒ¹é…: {images.shape[0]} vs {masks.shape[0]}")
            return False

        # æª¢æŸ¥ç¶­åº¦
        if len(images.shape) != 4:
            print(f"âŒ åœ–åƒå¼µé‡ç¶­åº¦ä¸æ­£ç¢º: {images.shape}ï¼ŒæœŸæœ› 4 ç¶­ (B,H,W,C)")
            return False

        if is_image_mask:
            # IMAGE é¡å‹é®ç½©æ‡‰è©²æ˜¯ 4 ç¶­ (B,H,W,C)
            if len(masks.shape) != 4:
                print(f"âŒ IMAGE é¡å‹é®ç½©å¼µé‡ç¶­åº¦ä¸æ­£ç¢º: {masks.shape}ï¼ŒæœŸæœ› 4 ç¶­ (B,H,W,C)")
                return False
        else:
            # MASK é¡å‹æ‡‰è©²æ˜¯ 3 ç¶­ (B,H,W)
            if len(masks.shape) != 3:
                print(f"âŒ MASK é¡å‹é®ç½©å¼µé‡ç¶­åº¦ä¸æ­£ç¢º: {masks.shape}ï¼ŒæœŸæœ› 3 ç¶­ (B,H,W)")
                return False

        return True

    def _prepare_batch_tensors(self, images: torch.Tensor, masks: torch.Tensor,
                               batch_indices: List[int], is_image_mask: bool = False,
                               interpolation_mode_str: str = "BICUBIC") -> Tuple[torch.Tensor, torch.Tensor, List[ImageTransformInfo]]:
        """
        æº–å‚™æ‰¹è™•ç†å¼µé‡ - ä½¿ç”¨ä¿æŒé•·å¯¬æ¯”çš„å¡«å……ç­–ç•¥
        è¿”å›ï¼š(æ‰¹è™•ç†åœ–åƒ, æ‰¹è™•ç†é®ç½©, è®Šæ›ä¿¡æ¯åˆ—è¡¨)
        """
        self._initialize_tensor_pool()

        batch_size = len(batch_indices)
        device = model_manager.device
        interpolation_mode = HighQualityImageProcessor.get_interpolation_mode(interpolation_mode_str)

        # å¾æ± ä¸­ç²å–æˆ–å‰µå»ºå¼µé‡
        batch_images = self.tensor_pool.get_tensor(
            (batch_size, 3, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)
        )
        batch_masks = self.tensor_pool.get_tensor(
            (batch_size, 1, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)
        )

        transform_infos = []

        # å¡«å……æ‰¹è™•ç†æ•¸æ“š
        for i, idx in enumerate(batch_indices):
            # è™•ç†åœ–åƒ - ä¿æŒé•·å¯¬æ¯”çš„å¡«å……
            image = images[idx].permute(2, 0, 1)  # HWC -> CHW

            # ã€é—œéµæ”¹é€²ã€‘ä½¿ç”¨ä¿æŒé•·å¯¬æ¯”çš„å¡«å……
            padded_image, transform_info = HighQualityImageProcessor.pad_to_square(
                image, MODEL_INPUT_SIZE, interpolation_mode
            )

            batch_images[i] = padded_image.to(device)
            transform_infos.append(transform_info)

            print(f"ğŸ–¼ï¸  åœ–åƒ {idx}: {transform_info.original_h}x{transform_info.original_w} â†’ "
                  f"{transform_info.scaled_h}x{transform_info.scaled_w} (å¡«å……åˆ° {MODEL_INPUT_SIZE}x{MODEL_INPUT_SIZE})")

            # è™•ç†é®ç½© - åŒæ¨£ä½¿ç”¨ä¿æŒé•·å¯¬æ¯”çš„é‚è¼¯
            mask = masks[idx]

            if is_image_mask:
                # IMAGE é¡å‹é®ç½© (H, W, C) - éœ€è¦è½‰æ›ç‚ºç°éš
                if mask.ndim == 3 and mask.shape[2] > 1:
                    if mask.shape[2] >= 3:
                        mask = 0.299 * mask[:, :, 0] + 0.587 * mask[:, :, 1] + 0.114 * mask[:, :, 2]
                    else:
                        mask = mask[:, :, 0]
                elif mask.ndim == 3 and mask.shape[2] == 1:
                    mask = mask[:, :, 0]
                print(f"ğŸ­ IMAGE é¡å‹é®ç½©è™•ç†å®Œæˆï¼Œå½¢ç‹€: {mask.shape}")
            else:
                # MASK é¡å‹é®ç½© (H, W)
                if mask.ndim == 3:
                    mask = mask[:, :, 0]
                print(f"ğŸ­ MASK é¡å‹é®ç½©è™•ç†å®Œæˆï¼Œå½¢ç‹€: {mask.shape}")

            # å°é®ç½©æ‡‰ç”¨ç›¸åŒçš„å¡«å……é‚è¼¯
            mask_chw = mask.unsqueeze(0)  # HW -> CHW
            padded_mask, _ = HighQualityImageProcessor.pad_to_square(
                mask_chw, MODEL_INPUT_SIZE, transforms.InterpolationMode.NEAREST  # é®ç½©ç”¨æœ€è¿‘é„°
            )

            batch_masks[i] = padded_mask.to(device)

            # èª¿è©¦ä¿¡æ¯
            print(f"ğŸ“Š æ¨£æœ¬ {idx}: é®ç½©å€¼ç¯„åœ [{padded_mask.min().item():.3f}, {padded_mask.max().item():.3f}]")

        return batch_images, batch_masks, transform_infos

    def _postprocess_results(self, results: torch.Tensor, original_shapes: List[Tuple[int, int]],
                             batch_indices: List[int]) -> List[torch.Tensor]:
        """å¾Œè™•ç†çµæœå¼µé‡"""
        processed_results = []

        for i, idx in enumerate(batch_indices):
            result = results[i:i + 1]  # ä¿æŒæ‰¹æ¬¡ç¶­åº¦
            h, w = original_shapes[idx]

            # ç¸®æ”¾å›åŸå§‹å°ºå¯¸
            result_resized = transforms.functional.resize(
                result, (h, w),
                interpolation=transforms.InterpolationMode.BILINEAR,
                antialias=True
            )

            # è½‰æ›ç‚º ComfyUI æ ¼å¼ (BCHW -> BHWC)
            result_comfy = result_resized.permute(0, 2, 3, 1).cpu()
            processed_results.append(result_comfy)

            # æ­¸é‚„å¼µé‡åˆ°æ± ä¸­
            if hasattr(self, 'tensor_pool') and self.tensor_pool:
                self.tensor_pool.return_tensor(result.detach())

        return processed_results

    def lama_remover(self, images: torch.Tensor, masks: torch.Tensor,
                     mask_threshold: int, gaussblur_radius: int, invert_mask: bool,
                     batch_size: int = 1, enable_performance_monitor: bool = False,
                     aggressive_normalization: bool = False, interpolation_mode: str = "BICUBIC",
                     is_image_mask: bool = False):
        """
        ã€å°ˆæ¥­ç´šå“è³ªç‰ˆæœ¬ã€‘æ¥µé™å„ªåŒ–çš„æ ¸å¿ƒè™•ç†å‡½å¼
        æ–°å¢å“è³ªæ”¹é€²ï¼š
        - ä¿æŒé•·å¯¬æ¯”çš„å¡«å……èˆ‡è£åˆ‡
        - å¯é¸çš„æ­£è¦åŒ–ç­–ç•¥
        - BICUBICé«˜å“è³ªæ’å€¼
        """
        # è¼¸å…¥é©—è­‰
        if not self._validate_inputs(images, masks, is_image_mask):
            return (images,)

        # æ€§èƒ½ç›£æ§è£é£¾å™¨
        monitor = performance_monitor if enable_performance_monitor else lambda x: contextmanager(lambda: (yield))()

        with monitor("ç¸½è™•ç†æ™‚é–“"):
            # æº–å‚™è™•ç†
            num_images = images.shape[0]
            results = []

            print(f"ğŸ¯ è™•ç†æ¨¡å¼: {'IMAGE é¡å‹é®ç½©' if is_image_mask else 'MASK é¡å‹é®ç½©'}")
            print(f"ğŸ¨ æ’å€¼æ¨¡å¼: {interpolation_mode}")
            print(f"ğŸ”§ æ­£è¦åŒ–ç­–ç•¥: {'æ¿€é€²æ‹‰ä¼¸' if aggressive_normalization else 'æº«å’Œé‰—ä½'}")

            # æ‰¹è™•ç†å¾ªç’°
            for start_idx in range(0, num_images, batch_size):
                end_idx = min(start_idx + batch_size, num_images)
                batch_indices = list(range(start_idx, end_idx))
                current_batch_size = len(batch_indices)

                with monitor(f"æ‰¹æ¬¡ {start_idx // batch_size + 1}/{(num_images - 1) // batch_size + 1}"):
                    try:
                        # ã€å“è³ªæ”¹é€²ã€‘æº–å‚™æ‰¹è™•ç†æ•¸æ“š - ä½¿ç”¨ä¿æŒé•·å¯¬æ¯”çš„å¡«å……
                        with monitor("é«˜å“è³ªæ•¸æ“šæº–å‚™"):
                            batch_images, batch_masks, transform_infos = self._prepare_batch_tensors(
                                images, masks, batch_indices, is_image_mask, interpolation_mode
                            )

                        # é®ç½©é è™•ç†
                        with monitor("é®ç½©è™•ç†"):
                            if invert_mask:
                                batch_masks = 1.0 - batch_masks

                            # æ‡‰ç”¨æ¨¡ç³Š
                            if gaussblur_radius > 0:
                                batch_masks = BlurProcessor.apply_blur(batch_masks, gaussblur_radius)

                            # äºŒå€¼åŒ–
                            threshold = mask_threshold / 255.0
                            batch_masks = (batch_masks > threshold).float()

                        # æ¨¡å‹æ¨ç†
                        with monitor("TensorRT æ¨ç†"):
                            with torch.no_grad():
                                # èª¿è©¦ï¼šé¡¯ç¤ºè¼¸å…¥æ•¸å€¼ç¯„åœ
                                print(f"ğŸ“Š è¼¸å…¥åœ–ç‰‡æ•¸å€¼ç¯„åœ: [{batch_images.min().item():.4f}, {batch_images.max().item():.4f}]")
                                print(f"ğŸ“Š è¼¸å…¥é®ç½©æ•¸å€¼ç¯„åœ: [{batch_masks.min().item():.4f}, {batch_masks.max().item():.4f}]")

                                batch_results = model_manager.model(batch_images, batch_masks)
                                torch.cuda.synchronize()

                        # ã€å“è³ªæ”¹é€²ã€‘çµæœå¾Œè™•ç†
                        with monitor("é«˜å“è³ªçµæœå¾Œè™•ç†"):
                            # ã€é¸æ“‡æ€§æ­£è¦åŒ–ã€‘æ ¹æ“šç”¨æˆ¶è¨­å®šé¸æ“‡ç­–ç•¥
                            batch_results = self._normalize_tensorrt_output(
                                batch_results, aggressive_normalization
                            )

                            # ã€ç²¾ç¢ºæ¢å¾©ã€‘ä½¿ç”¨è£åˆ‡å’Œç¸®æ”¾æ¢å¾©åŸå§‹å°ºå¯¸
                            processed = self._postprocess_results(
                                batch_results, transform_infos, batch_indices, interpolation_mode
                            )
                            results.extend(processed)

                    except Exception as e:
                        print(f"âŒ æ‰¹æ¬¡ {start_idx // batch_size + 1} è™•ç†å¤±æ•—: {e}")
                        # å‚™æ´ï¼šè¿”å›åŸå§‹åœ–åƒ
                        for idx in batch_indices:
                            results.append(images[idx:idx + 1])

                    # åŠæ™‚æ¸…ç† GPU å…§å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

        # åˆä½µæ‰€æœ‰çµæœ
        try:
            final_result = torch.cat(results, dim=0)
        except Exception as e:
            print(f"âŒ çµæœåˆä½µå¤±æ•—: {e}")
            final_result = images

        # æœ€çµ‚å…§å­˜æ¸…ç†
        if enable_performance_monitor:
            print(f"ğŸ§¹ æœ€çµ‚ GPU å…§å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024 / 1024:.1f}MB")

        return (final_result,)


class LamaRemoverIMG(LamaRemover):
    """
    LamaRemover çš„ IMAGE è¼¸å…¥è®Šé«”ï¼Œç¹¼æ‰¿æ‰€æœ‰å„ªåŒ–
    å°ˆé–€è™•ç† IMAGE é¡å‹çš„é®ç½©è¼¸å…¥
    """

    @classmethod
    def INPUT_TYPES(cls):
        base_inputs = super().INPUT_TYPES()
        base_inputs["required"]["masks"] = ("IMAGE",)  # æ”¹ç‚º IMAGE é¡å‹
        return base_inputs

    FUNCTION = "lama_remover_img"

    def lama_remover_img(self, images: torch.Tensor, masks: torch.Tensor,
                         mask_threshold: int, gaussblur_radius: int, invert_mask: bool,
                         batch_size: int = 1, enable_performance_monitor: bool = False):
        """
        IMAGE é¡å‹é®ç½©çš„è™•ç†å…¥å£ï¼Œèª¿ç”¨çˆ¶é¡æ–¹æ³•ä¸¦æ¨™è¨˜é®ç½©é¡å‹
        """
        return self.lama_remover(
            images=images,
            masks=masks,
            mask_threshold=mask_threshold,
            gaussblur_radius=gaussblur_radius,
            invert_mask=invert_mask,
            batch_size=batch_size,
            enable_performance_monitor=enable_performance_monitor,
            is_image_mask=True  # é—œéµï¼šæ¨™è¨˜ç‚º IMAGE é¡å‹é®ç½©
        )


# --- [å·¥å…·å‡½æ•¸] ---
def get_model_info():
    """ç²å–æ¨¡å‹è³‡è¨Šï¼ˆé™¤éŒ¯ç”¨ï¼‰"""
    try:
        info = model_manager.model.get_engine_info()
        return info
    except Exception as e:
        return {"error": str(e)}


def cleanup_resources():
    """æ¸…ç†è³‡æºï¼ˆå¯é¸çš„å¤–éƒ¨èª¿ç”¨ï¼‰"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()
    print("ğŸ§¹ è³‡æºæ¸…ç†å®Œæˆ")


# --- ComfyUI ç¯€é»è¨»å†Š ---
NODE_CLASS_MAPPINGS = {
    "LamaRemover": LamaRemover,
    "LamaRemoverIMG": LamaRemoverIMG
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LamaRemover": "ğŸš€ Big Lama Remover (æ¥µé™å„ªåŒ–ç‰ˆ)",
    "LamaRemoverIMG": "ğŸš€ Big Lama Remover IMG (æ¥µé™å„ªåŒ–ç‰ˆ)"
}