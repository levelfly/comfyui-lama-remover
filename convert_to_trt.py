# convert_to_trt_TensorRT10x_optimized.py (é‡å° TensorRT 10.x å’Œ RTX 3090 çš„å„ªåŒ–ç‰ˆæœ¬)
# ç‰ˆæœ¬ 2: ä¿®æ”¹ç‚ºæ”¯æ´å‹•æ…‹å°ºå¯¸ (Dynamic Shape) ä»¥ä¾¿ä½¿ç”¨ Padding ç­–ç•¥
import tensorrt as trt
import os
import sys

# --- ç‰ˆæœ¬æª¢æŸ¥å’Œè·¯å¾‘è¨­å®š ---
print(f"è…³æœ¬åŸ·è¡Œç•¶ä¸‹ï¼Œå¯¦éš›ä½¿ç”¨çš„ TensorRT ç‰ˆæœ¬æ˜¯: {trt.__version__}")

# TensorRT ç‰ˆæœ¬è§£æ
trt_version = trt.__version__
major_version = int(trt_version.split('.')[0])
print(f"TensorRT ä¸»ç‰ˆæœ¬: {major_version}")

# --- è·¯å¾‘è¨­å®š ---
ONNX_PATH = './ckpts/lama_fp32_dynamic.onnx'

# ComfyUI TRT æ¨¡å‹ç›®éŒ„è¨­å®š
TRT_MODEL_DIR = '/root/ComfyUI/models/trt'
# --- MODIFIED: æ›´æ”¹å¼•æ“æª”æ¡ˆåç¨±ä»¥åæ˜ å‹•æ…‹å°ºå¯¸ç‰¹æ€§ ---
ENGINE_FILENAME = f'lama_fp16_rtx3090_trt{major_version}x_dynamic.trt'
ENGINE_PATH = os.path.join(TRT_MODEL_DIR, ENGINE_FILENAME)

WORKSPACE_GB = 12  # RTX 3090 çš„ 24GB VRAM å¯ä»¥ä½¿ç”¨è¼ƒå¤§å·¥ä½œç©ºé–“

# ç¢ºä¿ TRT æ¨¡å‹ç›®éŒ„å­˜åœ¨
try:
    os.makedirs(TRT_MODEL_DIR, exist_ok=True)
    # æ¸¬è©¦å¯«å…¥æ¬Šé™
    test_file = os.path.join(TRT_MODEL_DIR, '.write_test')
    with open(test_file, 'w') as f:
        f.write('test')
    os.remove(test_file)

    print(f"âœ… TRT æ¨¡å‹ç›®éŒ„: {TRT_MODEL_DIR}")
    print(f"  - ç›®éŒ„å­˜åœ¨ä¸”å¯å¯«å…¥")
except PermissionError:
    print(f"âŒ æ¬Šé™éŒ¯èª¤: ç„¡æ³•å¯«å…¥ {TRT_MODEL_DIR}")
    print("å»ºè­°è§£æ±ºæ–¹æ¡ˆ:")
    print("  1. ä½¿ç”¨ sudo é‹è¡Œæ­¤è…³æœ¬")
    print("  2. æˆ–æ›´æ”¹ç›®éŒ„æ¬Šé™: sudo chmod 777 /root/ComfyUI/models/")
    sys.exit(1)
except Exception as e:
    print(f"âŒ ç›®éŒ„å‰µå»ºå¤±æ•—: {e}")
    sys.exit(1)

print("--- TensorRT å¼•æ“å»ºæ§‹å™¨ (TensorRT 10.x + RTX 3090 å°ˆç”¨å„ªåŒ–) ---")

if not os.path.exists(ONNX_PATH):
    print(f"éŒ¯èª¤ï¼šåœ¨ {ONNX_PATH} æ‰¾ä¸åˆ° ONNX æ¨¡å‹æª”æ¡ˆ")
    sys.exit(1)

# --- åˆå§‹åŒ– TensorRT å…ƒä»¶ ---
TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
builder = trt.Builder(TRT_LOGGER)
network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
config = builder.create_builder_config()
parser = trt.OnnxParser(network, TRT_LOGGER)

# --- è¨­å®šå»ºæ§‹æ™‚çš„è¨˜æ†¶é«” ---
config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, WORKSPACE_GB * (1 << 30))

print(f"\n=== TensorRT {major_version}.x + Ampere æ¶æ§‹ (RTX 3090) å„ªåŒ–è¨­å®š ===")

# 1. å•Ÿç”¨ FP16 æ¨¡å¼
config.set_flag(trt.BuilderFlag.FP16)
print("âœ“ å·²å•Ÿç”¨ FP16 åŠç²¾åº¦æµ®é»æ•¸æ¨¡å¼")

# 2. æª¢æŸ¥ç¡¬é«”æ”¯æ´
if builder.platform_has_fast_fp16:
    print("âœ“ ç¡¬é«”æ”¯æ´å¿«é€Ÿ FP16 (åµæ¸¬åˆ° Ampere æ¶æ§‹çš„å¼µé‡æ ¸å¿ƒ)")
else:
    print("âš  è­¦å‘Šï¼šç›®å‰çš„ç¡¬é«”å¯èƒ½ç„¡æ³•å¾ FP16 ä¸­ç²å¾—æœ€å¤§æ•ˆèƒ½")

# 3. TensorRT 10.x çš„ TF32 è™•ç†
if major_version >= 10:
    print("âœ“ TensorRT 10.x æª¢æ¸¬åˆ°:")
    print("  - TF32 åœ¨ Ampere GPU ä¸Šè‡ªå‹•å•Ÿç”¨ (ç„¡éœ€æ˜ç¢ºè¨­å®š)")
    print("  - äº«å— TF32 åŠ é€Ÿçš„ FP32 é‹ç®—å’Œ FP16 çš„é›™é‡å„ªå‹¢")
else:
    # TensorRT 8.x/9.x çš„è™•ç†æ–¹å¼
    try:
        config.set_flag(trt.BuilderFlag.TF32)
        print("âœ“ å·²å•Ÿç”¨ TF32 æ¨¡å¼ (TensorRT 8.x/9.x)")
    except AttributeError:
        print("â“˜ TF32 æ¨™èªŒä¸å¯ç”¨")

# 4. åš´æ ¼å‹åˆ¥æ¨¡å¼ (ç‰ˆæœ¬æª¢æŸ¥)
strict_types_available = False
try:
    config.set_flag(trt.BuilderFlag.STRICT_TYPES)
    print("âœ“ å·²å•Ÿç”¨åš´æ ¼å‹åˆ¥æ¨¡å¼ (STRICT_TYPES)")
    strict_types_available = True
except AttributeError:
    # å˜—è©¦è¼ƒèˆŠçš„æ›¿ä»£æ–¹æ¡ˆ
    try:
        config.set_flag(trt.BuilderFlag.DIRECT_IO)
        print("âœ“ å·²å•Ÿç”¨ DIRECT_IO æ¨¡å¼ (STRICT_TYPES çš„æ›¿ä»£)")
    except AttributeError:
        print("â“˜ ç²¾åº¦æ§åˆ¶æ¨™èªŒåœ¨æ­¤ç‰ˆæœ¬ä¸­ä¸å¯ç”¨")

# 5. TensorRT 10.x çš„é¡å¤–å„ªåŒ–
if major_version >= 10:
    # æª¢æŸ¥å¯ç”¨çš„æ–°æ¨™èªŒ
    available_flags = []

    # å˜—è©¦ä¸€äº› TensorRT 10.x çš„æ–°åŠŸèƒ½
    try:
        config.set_flag(trt.BuilderFlag.PREFER_PRECISION_CONSTRAINTS)
        available_flags.append("PREFER_PRECISION_CONSTRAINTS")
    except (AttributeError, Exception):
        pass

    try:
        config.set_flag(trt.BuilderFlag.SPARSE_WEIGHTS)
        available_flags.append("SPARSE_WEIGHTS")
    except (AttributeError, Exception):
        pass

    if available_flags:
        print(f"âœ“ TensorRT 10.x é¡å¤–å„ªåŒ–: {', '.join(available_flags)}")

# 6. é¡¯ç¤ºæ‰€æœ‰å¯ç”¨çš„ BuilderFlag (é™¤éŒ¯ç”¨)
print("\n--- å¯ç”¨çš„ BuilderFlag (é™¤éŒ¯è³‡è¨Š) ---")
all_flags = [attr for attr in dir(trt.BuilderFlag) if not attr.startswith('_')]
print(f"æ­¤ç‰ˆæœ¬æ”¯æ´çš„æ¨™èªŒæ•¸é‡: {len(all_flags)}")
print(f"é—œéµæ¨™èªŒæª¢æŸ¥:")
key_flags = ['FP16', 'TF32', 'STRICT_TYPES', 'PREFER_PRECISION_CONSTRAINTS']
for flag in key_flags:
    exists = hasattr(trt.BuilderFlag, flag)
    print(f"  - {flag}: {'âœ“' if exists else 'âœ—'}")

# --- è§£æ ONNX æ¨¡å‹ ---
print(f"\næ­£åœ¨å¾ {ONNX_PATH} è§£æ ONNX æ¨¡å‹...")
with open(ONNX_PATH, 'rb') as model:
    if not parser.parse(model.read()):
        print("éŒ¯èª¤ï¼šè§£æ ONNX æª”æ¡ˆå¤±æ•—ã€‚")
        for error in range(parser.num_errors):
            print(f"  - {parser.get_error(error)}")
        sys.exit(1)
print("ONNX æ¨¡å‹è§£ææˆåŠŸã€‚")

# æª¢æŸ¥ç¶²è·¯çš„è¼¸å…¥å’Œè¼¸å‡º
print("\n--- ç¶²è·¯è¼¸å…¥å±¤ ---")
for i in range(network.num_inputs):
    tensor = network.get_input(i)
    print(f"  è¼¸å…¥å±¤ {i}: åç¨±={tensor.name}, å½¢ç‹€={tensor.shape}, å‹åˆ¥={tensor.dtype}")

print("\n--- ç¶²è·¯è¼¸å‡ºå±¤ ---")
for i in range(network.num_outputs):
    tensor = network.get_output(i)
    print(f"  è¼¸å‡ºå±¤ {i}: åç¨±={tensor.name}, å½¢ç‹€={tensor.shape}, å‹åˆ¥={tensor.dtype}")

# --- MODIFIED: è¨­å®šæœ€ä½³åŒ–è¨­å®šæª” (æ”¹ç‚ºå‹•æ…‹å°ºå¯¸) ---
print("\n--- å‹•æ…‹å°ºå¯¸æœ€ä½³åŒ–è¨­å®šæª” (æ”¯æ´ Padding ç­–ç•¥) ---")
profile = builder.create_optimization_profile()

# ç‚º "image" è¼¸å…¥å®šç¾©å°ºå¯¸ç¯„åœ (Batch, Channels, Height, Width)
# æ³¨æ„ï¼šé•·å¯¬æœ€å¥½æ˜¯ 8 çš„å€æ•¸
min_shape = (1, 3, 256, 256)      # æœ€å°å¯è™•ç†å°ºå¯¸
opt_shape = (1, 3, 1024, 1024)      # é æœŸæœ€ä½³æ€§èƒ½çš„å°ºå¯¸
max_shape = (1, 3, 2560, 2560)    # æœ€å¤§å¯è™•ç†å°ºå¯¸ (RTX 3090 å¯è¨­æ›´é«˜)

# ç‚º "mask" è¼¸å…¥å®šç¾©å°æ‡‰çš„å°ºå¯¸ç¯„åœ
mask_min_shape = (1, 1, 256, 256)
mask_opt_shape = (1, 1, 1024, 1024)
mask_max_shape = (1, 1, 2560, 2560)
mask_input_name = "mask" # ç¢ºä¿èˆ‡æ‚¨æ¨¡å‹è¼¸å…¥åç¨±ä¸€è‡´

profile.set_shape("image", min=min_shape, opt=opt_shape, max=max_shape)
profile.set_shape(mask_input_name, min=mask_min_shape, opt=mask_opt_shape, max=mask_max_shape)
config.add_optimization_profile(profile)

print(f"âœ“ å·²ç‚ºè¼¸å…¥ 'image' å’Œ '{mask_input_name}' è¨­å®šå‹•æ…‹å°ºå¯¸")
print(f"  - æœ€å°å°ºå¯¸: {min_shape}")
print(f"  - æœ€ä½³å°ºå¯¸: {opt_shape}")
print(f"  - æœ€å¤§å°ºå¯¸: {max_shape}")
print(f"  - æ­¤å¼•æ“å°‡èƒ½è™•ç†æ­¤ç¯„åœå…§çš„ä»»æ„å°ºå¯¸ï¼Œé©åˆ Padding ç­–ç•¥ã€‚")


# --- å»ºæ§‹å¼•æ“ ---
print("\næ­£åœ¨å»ºæ§‹ TensorRT å¼•æ“...")
print("TensorRT 10.x æœƒè‡ªå‹•ç‚ºæ‚¨çš„ RTX 3090 é¸æ“‡æœ€å¿«çš„æ ¸å¿ƒ...")
print("å»ºæ§‹å‹•æ…‹å°ºå¯¸å¼•æ“å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å€™...")

serialized_engine = builder.build_serialized_network(network, config)

if serialized_engine is None:
    print("éŒ¯èª¤ï¼šå»ºæ§‹å¼•æ“å¤±æ•—ã€‚è«‹æª¢æŸ¥æ—¥èªŒè¨Šæ¯ã€‚")
    sys.exit(1)

print("âœ“ TensorRT å¼•æ“å»ºæ§‹æˆåŠŸï¼")

# --- å„²å­˜å¼•æ“åˆ° ComfyUI ç›®éŒ„ ---
with open(ENGINE_PATH, "wb") as f:
    f.write(serialized_engine)

print(f"âœ“ å¼•æ“å·²æˆåŠŸå„²å­˜è‡³ ComfyUI TRT æ¨¡å‹ç›®éŒ„:")
print(f"  - å®Œæ•´è·¯å¾‘: {ENGINE_PATH}")
print(f"  - æª”æ¡ˆåç¨±: {ENGINE_FILENAME}")

# é¡¯ç¤º ComfyUI ç›®éŒ„çµæ§‹
print(f"\n--- ComfyUI TRT ç›®éŒ„çµæ§‹ ---")
print(f"ğŸ“ {TRT_MODEL_DIR}/")
if os.path.exists(TRT_MODEL_DIR):
    trt_files = [f for f in os.listdir(TRT_MODEL_DIR) if f.endswith('.trt')]
    if trt_files:
        for trt_file in sorted(trt_files):
            file_path = os.path.join(TRT_MODEL_DIR, trt_file)
            file_size = os.path.getsize(file_path) / (1024 * 1024)
            marker = "ğŸ†•" if trt_file == ENGINE_FILENAME else "ğŸ“„"
            print(f"  {marker} {trt_file} ({file_size:.1f} MB)")
    else:
        print(f"  ğŸ“„ {ENGINE_FILENAME} (æ–°å»º)")

# é¡¯ç¤ºæª”æ¡ˆå¤§å°æ¯”è¼ƒ
if os.path.exists(ENGINE_PATH):
    engine_size_mb = os.path.getsize(ENGINE_PATH) / (1024 * 1024)
    print(f"\n--- æª”æ¡ˆå¤§å°è³‡è¨Š ---")
    print(f"  - TRT å¼•æ“å¤§å°: {engine_size_mb:.2f} MB")

if os.path.exists(ONNX_PATH):
    onnx_size_mb = os.path.getsize(ONNX_PATH) / (1024 * 1024)
    print(f"  - åŸå§‹ ONNX å¤§å°: {onnx_size_mb:.2f} MB")
    if os.path.exists(ENGINE_PATH):
        compression_ratio = (onnx_size_mb - engine_size_mb) / onnx_size_mb * 100
        if compression_ratio > 0:
            print(f"  - å¤§å°æ¸›å°‘: {compression_ratio:.1f}%")
        else:
            print(f"  - å¤§å°å¢åŠ : {abs(compression_ratio):.1f}% (åŒ…å«å„ªåŒ–è³‡æ–™)")

print("\n" + "=" * 70)
print("=== TensorRT 10.x + RTX 3090 + ComfyUI æœ€çµ‚å„ªåŒ–å®Œæˆï¼ ===")
print("=" * 70)
print("ğŸ¯ å¼•æ“å·²æˆåŠŸå»ºç«‹ä¸¦å„²å­˜åˆ° ComfyUI æ¨¡å‹ç›®éŒ„:")
print(f"   ğŸ“ {TRT_MODEL_DIR}/")
print(f"   ğŸ“„ {ENGINE_FILENAME}")
print("\nâœ… å„ªåŒ–ç‰¹é»:")
print("  ğŸš€ FP16 åŠ é€Ÿ: å……åˆ†åˆ©ç”¨ Ampere æ¶æ§‹çš„ç¬¬ä¸‰ä»£ Tensor Cores")
print("  âš¡ TF32 è‡ªå‹•å•Ÿç”¨: TensorRT 10.x åœ¨ RTX 3090 ä¸Šçš„é è¨­è¡Œç‚º")
print("  ğŸ¤¸ **å°ºå¯¸éˆæ´»æ€§**: é€éå‹•æ…‹å°ºå¯¸è¨­å®šï¼Œå¯è™•ç†ä¸åŒè§£æåº¦ï¼Œæ”¯æ´ Padding ç­–ç•¥") # MODIFIED
print("  ğŸ†• ç¾ä»£åŒ–: ä½¿ç”¨ TensorRT 10.x çš„æœ€æ–°å„ªåŒ–æŠ€è¡“")
print(f"  ğŸ“ˆ é æœŸæ€§èƒ½: RTX 3090 ä¸Šç´„ 2-3x åŠ é€Ÿ (ç›¸è¼ƒæ–¼åŸå§‹ FP32)")

print(f"\nğŸ’¡ åœ¨ ComfyUI ä¸­ä½¿ç”¨:")
print(f"  1. å¼•æ“æª”æ¡ˆå·²æ”¾ç½®åœ¨æ­£ç¢ºçš„ TRT æ¨¡å‹ç›®éŒ„ä¸­")
print(f"  2. **é‡è¦**: æ‚¨éœ€è¦ä¿®æ”¹ ComfyUI ç¯€é»çš„ Python ç¨‹å¼ç¢¼ï¼Œå°‡åœ–ç‰‡é è™•ç†å¾ã€å¼·åˆ¶ç¸®æ”¾ã€æ”¹ç‚ºã€Paddingã€ï¼Œä»¥åˆ©ç”¨æ­¤å¼•æ“çš„å‹•æ…‹ç‰¹æ€§ã€‚")
print(f"  3. ComfyUI LaMa Remover ç¯€é»æ‡‰è©²èƒ½è‡ªå‹•è­˜åˆ¥æ­¤å¼•æ“")
print(f"  4. é¸æ“‡ä½¿ç”¨ TensorRT æ¨ç†æ¨¡å¼ä»¥ç²å¾—æœ€ä½³æ€§èƒ½")

# é©—è­‰ TF32 ç‹€æ…‹çš„é¡å¤–è³‡è¨Š
print(f"\nğŸ”§ TF32 ç‹€æ…‹ç¢ºèª:")
print(f"âœ… æ‚¨çš„è¨­å®šçµ„åˆ (RTX 3090 + TensorRT {trt_version}) ä¸­:")
print(f"  - TF32 åœ¨ Tensor Core é‹ç®—ä¸­è‡ªå‹•å•Ÿç”¨")
print(f"  - ç„¡éœ€æ˜ç¢ºè¨­å®šï¼Œé€™æ˜¯ TensorRT 10.x çš„è¨­è¨ˆæ”¹é€²")
print(f"  - æ‚¨å°‡è‡ªå‹•ç²å¾— TF32 çš„æ€§èƒ½å„ªå‹¢")

print(f"\nğŸ“ æŠ€è¡“ç´°ç¯€:")
print(f"  - å·¥ä½œç©ºé–“: {WORKSPACE_GB}GB (å……åˆ†åˆ©ç”¨ RTX 3090 çš„ 24GB VRAM)")
print(f"  - æ‰¹æ¬¡å¤§å°: 1 (å°ˆç‚º ComfyUI å–®å¼µåœ–ç‰‡è™•ç†å„ªåŒ–)")
print(f"  - è¼¸å…¥è§£æåº¦: å‹•æ…‹ (Min: {min_shape[2]}x{min_shape[3]}, Opt: {opt_shape[2]}x{opt_shape[3]}, Max: {max_shape[2]}x{max_shape[3]})") # MODIFIED
print(f"  - ç²¾åº¦æ¨¡å¼: FP16 + è‡ªå‹• TF32")